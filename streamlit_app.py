import streamlit as st
import numpy as np
import pandas as pd
import pickle
import matplotlib.pyplot as plt
import warnings
import os
import sys
from pathlib import Path
from scipy import stats

# å¯¼å…¥å¹¶åº”ç”¨äº‘ç«¯å…¼å®¹æ€§ä¿®å¤
try:
    from cloud_compatibility_fix import apply_numpy_compatibility_patch
    apply_numpy_compatibility_patch()
except ImportError:
    # å¦‚æœä¿®å¤è„šæœ¬ä¸å­˜åœ¨ï¼Œä½¿ç”¨å†…ç½®è¡¥ä¸
    try:
        if not hasattr(np, 'int'):
            np.int = int
        if not hasattr(np, 'float'):
            np.float = float
        if not hasattr(np, 'bool'):
            np.bool = bool
        if not hasattr(np, 'complex'):
            np.complex = complex
        print("âœ… å†…ç½®NumPyå…¼å®¹æ€§è¡¥ä¸å·²åº”ç”¨")
    except Exception as e:
        print(f"âš ï¸ NumPyå…¼å®¹æ€§è¡¥ä¸å¤±è´¥: {e}")
except Exception as e:
    print(f"âš ï¸ äº‘ç«¯å…¼å®¹æ€§ä¿®å¤å¤±è´¥: {e}")

# ä¿®å¤numpyå…¼å®¹æ€§é—®é¢˜ - äº‘ç«¯ç¯å¢ƒ
try:
    # æ·»åŠ å…¼å®¹æ€§è¡¥ä¸ï¼Œé€‚é…æ–°ç‰ˆnumpy
    if not hasattr(np, 'int'):
        np.int = int
    if not hasattr(np, 'float'):
        np.float = float
    if not hasattr(np, 'bool'):
        np.bool = bool
    if not hasattr(np, 'complex'):
        np.complex = complex
    print("âœ… NumPyå…¼å®¹æ€§è¡¥ä¸å·²åº”ç”¨")
except Exception as e:
    print(f"âš ï¸ NumPyå…¼å®¹æ€§è¡¥ä¸å¤±è´¥: {e}")

# ä¿®å¤numpyå…¼å®¹æ€§é—®é¢˜ - äº‘ç«¯ç¯å¢ƒ
try:
    # æ·»åŠ å…¼å®¹æ€§è¡¥ä¸ï¼Œé€‚é…æ–°ç‰ˆnumpy
    if not hasattr(np, 'int'):
        np.int = int
    if not hasattr(np, 'float'):
        np.float = float
    if not hasattr(np, 'bool'):
        np.bool = bool
    if not hasattr(np, 'complex'):
        np.complex = complex
    print("âœ… NumPyå…¼å®¹æ€§è¡¥ä¸å·²åº”ç”¨")
except Exception as e:
    print(f"âš ï¸ NumPyå…¼å®¹æ€§è¡¥ä¸å¤±è´¥: {e}")

# å®‰å…¨å¯¼å…¥SHAP - å¦‚æœå¤±è´¥ä¹Ÿä¸å½±å“ä¸»è¦åŠŸèƒ½
SHAP_AVAILABLE = True
try:
    import shap
    print("âœ… SHAPåº“å¯¼å…¥æˆåŠŸ")
except ImportError as e:
    SHAP_AVAILABLE = False
    print(f"âš ï¸ SHAPæœªå®‰è£…: {e}")
except Exception as e:
    SHAP_AVAILABLE = False
    print(f"âš ï¸ SHAPå¯¼å…¥é”™è¯¯: {e}")
except Exception as e:
    SHAP_AVAILABLE = False
    print(f"âš ï¸ SHAPå¯¼å…¥é”™è¯¯: {e}")

# è·å–å½“å‰ç›®å½•è·¯å¾„
current_dir = Path(__file__).parent
sys.path.append(str(current_dir))

warnings.filterwarnings("ignore")

# è®¾ç½®é¡µé¢é…ç½®
st.set_page_config(
    page_title="Depression Scale Score Prediction",
    page_icon="ğŸ§ ",
    layout="centered",
    initial_sidebar_state="collapsed"
)

# ç®€æ´çš„CSSæ ·å¼ - ç™½åº•é»‘å­—
st.markdown("""
<style>
    .stApp {
        background-color: white;
    }
    .main-title {
        font-size: 28px;
        font-weight: bold;
        color: #000000;
        text-align: center;
        margin-bottom: 10px;
        margin-top: 5px;
    }
    .model-section {
        margin-bottom: 0px;
    }
    .input-section {
        background-color: #f8f9fa;
        padding: 15px;
        border-radius: 8px;
        margin: 0px 0 10px 0;
        border: 1px solid #e9ecef;
    }
    .input-container {
        display: flex;
        flex-direction: column;
        align-items: stretch;
        height: 110px;
        margin-bottom: 15px;
    }
    .input-label {
        font-size: 16px;
        font-weight: 500;
        color: #000000;
        margin-bottom: 8px;
        text-align: left;
        min-height: 35px;
        display: flex;
        align-items: center;
    }
    .input-number {
        background-color: #2c3e50;
        color: white;
        border: none;
        border-radius: 8px;
        padding: 12px;
        font-size: 16px;
        font-weight: bold;
        text-align: center;
        flex-grow: 1;
        margin-top: auto;
    }
    .prediction-container {
        background-color: #ffffff;
        border: 2px solid #dee2e6;
        border-radius: 8px;
        padding: 20px;
        margin: 5px 0;
    }
    .prediction-box {
        text-align: center;
        margin-bottom: 15px;
    }
    .prediction-text {
        font-size: 18px;
        color: #000000;
        font-style: italic;
        margin-bottom: 10px;
    }
    .prediction-value {
        font-size: 24px;
        font-weight: bold;
        color: #000000;
        margin-bottom: 5px;
    }
    .confidence-interval {
        font-size: 16px;
        color: #666666;
        margin-top: 10px;
    }
    .score-details {
        display: flex;
        justify-content: space-around;
        margin-top: 15px;
        padding: 15px;
        background-color: #f8f9fa;
        border-radius: 5px;
    }
    .score-item {
        text-align: center;
    }
    .score-label {
        font-size: 14px;
        color: #666666;
        margin-bottom: 5px;
    }
    .score-value {
        font-size: 18px;
        font-weight: bold;
        color: #2c3e50;
    }
    .model-select {
        margin-bottom: 0px;
    }
    .predict-button {
        width: 100%;
        background-color: #2c3e50;
        color: white;
        border: none;
        padding: 15px 20px;
        border-radius: 8px;
        font-size: 18px;
        font-weight: bold;
        margin: 10px 0;
        cursor: pointer;
        transition: background-color 0.3s ease;
    }
    .predict-button:hover {
        background-color: #34495e;
        box-shadow: 0 4px 8px rgba(0,0,0,0.2);
    }
    .shap-section {
        margin-top: 30px;
        padding: 20px;
        background-color: #ffffff;
    }
    .stNumberInput > div > div > input {
        background-color: #2c3e50 !important;
        color: white !important;
        border: none !important;
        border-radius: 8px !important;
        padding: 12px !important;
        font-size: 16px !important;
        font-weight: bold !important;
        text-align: center !important;
        height: 50px !important;
    }
    .stSelectbox > div > div > div {
        background-color: #2c3e50 !important;
        color: white !important;
        border-radius: 8px !important;
    }
    div[data-testid="stNumberInput"] {
        height: 70px;
    }
</style>
""", unsafe_allow_html=True)

class DepressionPredictionApp:
    def __init__(self):
        self.models = {}
        # åŠ è½½æ‰€æœ‰å¯ç”¨çš„æ¨¡å‹
        self.available_models = [
            'XGBoost', 'LightGBM', 'RandomForest', 'GradientBoosting', 
            'ExtraTrees', 'AdaBoost', 'SVM', 'ANN', 'DecisionTree', 
            'EnsembleBagging', 'KNN', 'LinearRegression', 'Ridge'
        ]
        
        # ç‰¹å¾åç§°æ˜ å°„
        self.feature_names = ['äº²å­é‡è¡¨æ€»å¾—åˆ†', 'éŸ§æ€§é‡è¡¨æ€»å¾—åˆ†', 'ç„¦è™‘é‡è¡¨æ€»å¾—åˆ†', 'æ‰‹æœºä½¿ç”¨æ—¶é—´æ€»å¾—åˆ†']
        self.feature_name_mapping = {
            'äº²å­é‡è¡¨æ€»å¾—åˆ†': 'Parent-Child Scale',
            'éŸ§æ€§é‡è¡¨æ€»å¾—åˆ†': 'Resilience Scale', 
            'ç„¦è™‘é‡è¡¨æ€»å¾—åˆ†': 'Anxiety Scale',
            'æ‰‹æœºä½¿ç”¨æ—¶é—´æ€»å¾—åˆ†': 'Phone Usage Time'
        }
        
        self.load_models()
        self.load_background_data()
    
    def load_models(self):
        """æ”¹è¿›çš„æ¨¡å‹åŠ è½½æ–¹æ³• - æ”¯æŒå¤šç§åŠ è½½æ–¹å¼"""
        models_dir = current_dir / 'models'
        loaded_models = []
        
        # å®šä¹‰è¦åŠ è½½çš„6ä¸ªæ¨¡å‹æ–‡ä»¶åæ˜ å°„
        selected_model_files = {
            'XGBoost': 'XGBoost_model.pkl',
            'LightGBM': 'LightGBM_model.pkl', 
            'KNN': 'KNN_model.pkl',
            'LinearRegression': 'LinearRegression_model.pkl',
            'Ridge': 'Ridge_model.pkl',
            'ANN': 'ANN_model.pkl'
        }
        
        print(f"ğŸ” Starting to load models...")
        
        for model_name, file_name in selected_model_files.items():
            print(f"Attempting to load {model_name}...")
            model_path = models_dir / file_name
            if model_path.exists():
                try:
                    # æŠ‘åˆ¶æ‰€æœ‰è­¦å‘Š
                    with warnings.catch_warnings():
                        warnings.simplefilter("ignore")
                        
                        # å°è¯•å¤šç§åŠ è½½æ–¹å¼
                        model = None
                        
                        # æ–¹æ³•1: æ ‡å‡†pickleåŠ è½½
                        try:
                            with open(model_path, 'rb') as f:
                                model = pickle.load(f)
                            print(f"âœ… {model_name} loaded successfully using standard pickle")
                        except Exception as e1:
                            print(f"âš ï¸ {model_name} standard pickle loading failed: {e1}")
                            
                            # æ–¹æ³•2: å°è¯•joblibåŠ è½½
                            try:
                                import joblib
                                model = joblib.load(model_path)
                                print(f"âœ… {model_name} loaded successfully using joblib")
                            except Exception as e2:
                                print(f"âš ï¸ {model_name} joblib loading failed: {e2}")
                                
                                # æ–¹æ³•3: å°è¯•ä½¿ç”¨latin1ç¼–ç 
                                try:
                                    with open(model_path, 'rb') as f:
                                        model = pickle.load(f, encoding='latin1')
                                    print(f"âœ… {model_name} loaded successfully using latin1 encoding")
                                except Exception as e3:
                                    print(f"âš ï¸ {model_name} latin1 encoding loading failed: {e3}")
                                    continue
                        
                        if model is None:
                            continue
                            
                    # æµ‹è¯•æ¨¡å‹æ˜¯å¦å¯ç”¨ï¼Œæ ¹æ®æ¨¡å‹ç±»å‹ä½¿ç”¨ä¸åŒçš„ç‰¹å¾åç§°
                    try:
                        # è®¾ç½®CPUç¯å¢ƒå˜é‡é¿å…GPUé—®é¢˜
                        import os
                        os.environ['CUDA_VISIBLE_DEVICES'] = ''
                        
                        # æ ¹æ®æ¨¡å‹ç±»å‹é€‰æ‹©ç‰¹å¾åç§°
                        if model_name in ['XGBoost']:
                            # XGBoostä½¿ç”¨è‹±æ–‡ç‰¹å¾å
                            test_data = pd.DataFrame({
                                'parent_child_score': [17],
                                'resilience_score': [7],
                                'anxiety_score': [4],
                                'phone_usage_score': [23]
                            })
                        else:
                            # å…¶ä»–æ¨¡å‹ä½¿ç”¨ä¸­æ–‡ç‰¹å¾å
                            test_data = pd.DataFrame({
                                'äº²å­é‡è¡¨æ€»å¾—åˆ†': [17],
                                'éŸ§æ€§é‡è¡¨æ€»å¾—åˆ†': [7],
                                'ç„¦è™‘é‡è¡¨æ€»å¾—åˆ†': [4],
                                'æ‰‹æœºä½¿ç”¨æ—¶é—´æ€»å¾—åˆ†': [23]
                            })
                        
                        _ = model.predict(test_data)
                        print(f"âœ… {model_name} model validation successful")
                    except Exception as test_error:
                        print(f"âš ï¸ {model_name} model validation failed: {test_error}")
                        # Still add to model list, handle compatibility when using
                    
                    self.models[model_name] = model
                    loaded_models.append(model_name)
                    print(f"âœ… æˆåŠŸåŠ è½½æ¨¡å‹: {model_name}")
                    
                except Exception as e:
                    print(f"âŒ æ— æ³•åŠ è½½æ¨¡å‹ {model_name}: {e}")
                    continue
            else:
                print(f"âš ï¸ æ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨: {file_name}")
        
        # Update available model list to actually loaded models
        self.available_models = loaded_models
        print(f"ğŸ“Š Total loaded {len(self.available_models)} models: {', '.join(self.available_models)}")
    
    def load_background_data(self):
        """Load background data for SHAP analysis and confidence interval calculation"""
        try:
            # å°è¯•åŠ è½½é¢„ç”Ÿæˆçš„èƒŒæ™¯æ•°æ®
            background_data_path = current_dir / 'models' / 'background_data.pkl'
            background_data_cn_path = current_dir / 'models' / 'background_data_cn.pkl'
            
            if background_data_path.exists() and background_data_cn_path.exists():
                # åŠ è½½è‹±æ–‡å’Œä¸­æ–‡ç‰¹å¾åç§°çš„èƒŒæ™¯æ•°æ®
                with open(background_data_path, 'rb') as f:
                    self.background_data_en = pickle.load(f)
                with open(background_data_cn_path, 'rb') as f:
                    self.background_data_cn = pickle.load(f)
                print(f"âœ… å·²åŠ è½½é¢„ç”Ÿæˆçš„èƒŒæ™¯æ•°æ®")
            else:
                # å›é€€åˆ°ä»CSVåŠ è½½æ•°æ®
                data_path = current_dir / 'data' / 'é‡è¡¨æ€»åˆ†å®Œæ•´æ•°æ®.csv'
                if data_path.exists():
                    df = pd.read_csv(data_path)
                    # éšæœºé‡‡æ ·500ä¸ªæ ·æœ¬ä½œä¸ºèƒŒæ™¯æ•°æ®
                    sample_data = df[self.feature_names].sample(n=min(500, len(df)), random_state=42)
                    
                    # åˆ›å»ºè‹±æ–‡ç‰¹å¾åç§°çš„èƒŒæ™¯æ•°æ®
                    self.background_data_en = sample_data.rename(columns={
                        'äº²å­é‡è¡¨æ€»å¾—åˆ†': 'parent_child_score',
                        'éŸ§æ€§é‡è¡¨æ€»å¾—åˆ†': 'resilience_score', 
                        'ç„¦è™‘é‡è¡¨æ€»å¾—åˆ†': 'anxiety_score',
                        'æ‰‹æœºä½¿ç”¨æ—¶é—´æ€»å¾—åˆ†': 'phone_usage_score'
                    })
                    
                    # ä¸­æ–‡ç‰¹å¾åç§°çš„èƒŒæ™¯æ•°æ®ä¿æŒåŸæ ·
                    self.background_data_cn = sample_data
                    
                    print(f"âœ… ä»CSVæ–‡ä»¶åŠ è½½èƒŒæ™¯æ•°æ®")
                    
                    # åŠ è½½å®Œæ•´æ•°æ®ç”¨äºç½®ä¿¡åŒºé—´ä¼°ç®—
                    self.full_data = df
                else:
                    st.error("æ‰¾ä¸åˆ°æ•°æ®æ–‡ä»¶å’Œé¢„ç”Ÿæˆçš„èƒŒæ™¯æ•°æ®")
                    self.background_data_en = None
                    self.background_data_cn = None
                    self.full_data = None
                    
        except Exception as e:
            st.error(f"åŠ è½½æ•°æ®å¤±è´¥: {e}")
            self.background_data_en = None
            self.background_data_cn = None
            self.full_data = None
    
    def calculate_prediction_confidence(self, model, model_name, input_data, n_bootstrap=50):
        """è®¡ç®—é¢„æµ‹ç½®ä¿¡åŒºé—´ - ç®€åŒ–ç‰ˆæœ¬ï¼Œäº‘ç«¯å‹å¥½"""
        try:
            # è·å–åŸºç¡€é¢„æµ‹
            base_prediction = model.predict(input_data)[0]
            
            # åŸºäºæ¨¡å‹ç±»å‹è®¾ç½®ä¸ç¡®å®šæ€§ç³»æ•°
            if model_name in ['XGBoost', 'LightGBM']:
                uncertainty_factor = 0.06  # 6%çš„ä¸ç¡®å®šæ€§ï¼Œæ ‘æ¨¡å‹ç›¸å¯¹å‡†ç¡®
            elif model_name in ['ANN']:
                uncertainty_factor = 0.12  # 12%çš„ä¸ç¡®å®šæ€§ï¼Œç¥ç»ç½‘ç»œ
            elif model_name in ['LinearRegression', 'Ridge']:
                uncertainty_factor = 0.08  # 8%çš„ä¸ç¡®å®šæ€§ï¼Œçº¿æ€§æ¨¡å‹æ¯”è¾ƒç¨³å®š
            elif model_name in ['KNN']:
                uncertainty_factor = 0.10  # 10%çš„ä¸ç¡®å®šæ€§
            else:
                uncertainty_factor = 0.08  # é»˜è®¤8%
            
            # è®¡ç®—æ ‡å‡†è¯¯å·®ï¼ˆåŸºäºé¢„æµ‹å€¼çš„åˆç†èŒƒå›´ï¼‰
            std_error = max(0.5, base_prediction * uncertainty_factor)
            
            # è®¡ç®—95%ç½®ä¿¡åŒºé—´ (ä½¿ç”¨tåˆ†å¸ƒè¿‘ä¼¼)
            margin_of_error = 1.96 * std_error
            lower_ci = max(0, base_prediction - margin_of_error)
            upper_ci = min(27, base_prediction + margin_of_error)
            
            return base_prediction, lower_ci, upper_ci
                
        except Exception as e:
            print(f"Confidence interval calculation error: {e}")
            # Return basic prediction and simple estimated confidence interval
            try:
                base_prediction = model.predict(input_data)[0]
                simple_margin = base_prediction * 0.1  # Simple 10% margin
                lower_ci = max(0, base_prediction - simple_margin)
                upper_ci = min(27, base_prediction + simple_margin)
                return base_prediction, lower_ci, upper_ci
            except:
                return None, None, None
    
    def create_shap_waterfall_plot(self, explainer, shap_values, input_data):
        """Create SHAP waterfall plot for clearer interpretability visualization"""
        try:
            import matplotlib.pyplot as plt
            import matplotlib.patches as patches
            print(f"Starting to create SHAP waterfall plot...")
            
            # Force clear matplotlib cache and reconfigure
            plt.style.use('default')
            plt.rcParams.clear()
            plt.rcParams.update(plt.rcParamsDefault)
            plt.switch_backend('Agg')
            
            # Set high-quality chart parameters
            plt.rcParams['figure.facecolor'] = 'white'
            plt.rcParams['axes.facecolor'] = 'white'
            plt.rcParams['figure.dpi'] = 150
            plt.rcParams['savefig.dpi'] = 200
            plt.rcParams['font.size'] = 12
            
            # Get baseline values and SHAP values
            expected_value = explainer.expected_value
            if hasattr(expected_value, '__len__') and len(expected_value) > 1:
                expected_value = expected_value[0]
            
            if len(shap_values.shape) > 1:
                shap_vals = shap_values[0]
            else:
                shap_vals = shap_values
            
            # ä½¿ç”¨åŸç”ŸSHAP waterfall plot
            try:
                import shap
                print("Using native SHAP waterfall plot...")
                
                # Create larger figure
                fig = plt.figure(figsize=(16, 10))
                fig.patch.set_facecolor('white')
                
                # Use English feature names to avoid encoding issues
                feature_name_mapping = {
                    'äº²å­é‡è¡¨æ€»å¾—åˆ†': 'Parent-Child Scale',
                    'éŸ§æ€§é‡è¡¨æ€»å¾—åˆ†': 'Resilience Scale', 
                    'ç„¦è™‘é‡è¡¨æ€»å¾—åˆ†': 'Anxiety Scale',
                    'æ‰‹æœºä½¿ç”¨æ—¶é—´æ€»å¾—åˆ†': 'Phone Usage Scale',
                    'parent_child_score': 'Parent-Child Scale',
                    'resilience_score': 'Resilience Scale',
                    'anxiety_score': 'Anxiety Scale', 
                    'phone_usage_score': 'Phone Usage Scale'
                }
                
                # Convert feature names to English
                english_feature_names = [feature_name_mapping.get(name, name) for name in input_data.columns.tolist()]
                
                # Use SHAP waterfall plot
                shap.plots.waterfall(shap.Explanation(
                    values=shap_vals,
                    base_values=expected_value,
                    data=input_data.iloc[0].values,
                    feature_names=english_feature_names
                ), show=False)
                
                plt.tight_layout()
                print("âœ… Native SHAP waterfall plot created successfully")
                return fig
                
            except Exception as waterfall_error:
                print(f"Native waterfall plot failed: {waterfall_error}")
                
                # Backup: Use simplified waterfall implementation
                print("Using backup waterfall implementation...")
                
                fig, ax = plt.subplots(figsize=(12, 8))
                fig.patch.set_facecolor('white')
                
                # Get feature information - uniformly use English to avoid encoding issues
                feature_values = input_data.iloc[0].values
                feature_name_mapping = {
                    'äº²å­é‡è¡¨æ€»å¾—åˆ†': 'Parent-Child Scale',
                    'éŸ§æ€§é‡è¡¨æ€»å¾—åˆ†': 'Resilience Scale', 
                    'ç„¦è™‘é‡è¡¨æ€»å¾—åˆ†': 'Anxiety Scale',
                    'æ‰‹æœºä½¿ç”¨æ—¶é—´æ€»å¾—åˆ†': 'Phone Usage Scale',
                    'parent_child_score': 'Parent-Child Scale',
                    'resilience_score': 'Resilience Scale',
                    'anxiety_score': 'Anxiety Scale', 
                    'phone_usage_score': 'Phone Usage Scale'
                }
                feature_names = [feature_name_mapping.get(name, name) for name in input_data.columns.tolist()]
                
                # åˆ›å»ºwaterfallæ•°æ®
                waterfall_data = []
                waterfall_data.append(('Base', expected_value, expected_value))
                
                current_value = expected_value
                for i, (name, value, shap_val) in enumerate(zip(feature_names, feature_values, shap_vals)):
                    waterfall_data.append((f'{name}\n({value:.1f})', shap_val, current_value + shap_val))
                    current_value += shap_val
                
                # ç»˜åˆ¶waterfallå›¾
                x_pos = range(len(waterfall_data))
                colors = ['gray'] + ['#ff6b6b' if d[1] > 0 else '#4ecdc4' for d in waterfall_data[1:]]
                
                for i, (label, contribution, cumulative) in enumerate(waterfall_data):
                    if i == 0:  # Base value
                        ax.bar(i, cumulative, color=colors[i], alpha=0.7, width=0.6)
                        ax.text(i, cumulative + 0.5, f'{cumulative:.2f}', 
                               ha='center', va='bottom', fontweight='bold', fontsize=11)
                    else:
                        # æ˜¾ç¤ºè´¡çŒ®å€¼
                        prev_cumulative = waterfall_data[i-1][2]
                        if contribution > 0:
                            ax.bar(i, contribution, bottom=prev_cumulative, 
                                  color=colors[i], alpha=0.8, width=0.6)
                            ax.text(i, prev_cumulative + contribution/2, f'+{contribution:.2f}', 
                                   ha='center', va='center', fontweight='bold', fontsize=10, color='white')
                        else:
                            ax.bar(i, abs(contribution), bottom=cumulative, 
                                  color=colors[i], alpha=0.8, width=0.6)
                            ax.text(i, cumulative + abs(contribution)/2, f'{contribution:.2f}', 
                                   ha='center', va='center', fontweight='bold', fontsize=10, color='white')
                        
                        # ç´¯ç§¯å€¼æ ‡ç­¾
                        ax.text(i, cumulative + 0.3, f'{cumulative:.2f}', 
                               ha='center', va='bottom', fontweight='bold', fontsize=11)
                
                # è®¾ç½®æ ‡ç­¾å’Œæ ·å¼
                ax.set_xticks(x_pos)
                ax.set_xticklabels([d[0] for d in waterfall_data], rotation=45, ha='right')
                ax.set_ylabel('Value', fontsize=12, fontweight='bold')
                ax.set_title('SHAP Waterfall Plot - Feature Contributions to Depression Prediction', 
                           fontsize=14, fontweight='bold', pad=20)
                
                # æ·»åŠ ç½‘æ ¼
                ax.grid(True, alpha=0.3, axis='y')
                ax.set_axisbelow(True)
                
                plt.tight_layout()
                print("âœ… Backup waterfall plot created successfully")
                return fig
            
        except Exception as e:
            st.error(f"åˆ›å»ºSHAPå›¾è¡¨å¤±è´¥: {e}")
            print(f"SHAPå›¾è¡¨é”™è¯¯è¯¦æƒ…: {e}")
            import traceback
            traceback.print_exc()
            return None
    
    def generate_simple_explanation(self, explainer, shap_values, input_data, model_name, prediction):
        """Provide concise and beautiful explanation for each test result"""
        try:
            # Get feature values and names
            feature_values = input_data.iloc[0].values
            feature_names = ['äº²å­é‡è¡¨æ€»å¾—åˆ†', 'éŸ§æ€§é‡è¡¨æ€»å¾—åˆ†', 'ç„¦è™‘é‡è¡¨æ€»å¾—åˆ†', 'æ‰‹æœºä½¿ç”¨æ—¶é—´æ€»å¾—åˆ†']
            
            # Get baseline values and SHAP values
            expected_value = explainer.expected_value
            if hasattr(expected_value, '__len__') and len(expected_value) > 1:
                expected_value = expected_value[0]
            
            if len(shap_values.shape) > 1:
                shap_vals = shap_values[0]
            else:
                shap_vals = shap_values
            
            # Risk level assessment
            if prediction > 14:
                risk_level = "High Risk"
                risk_color = "#e74c3c"
                risk_emoji = "ğŸ”´"
            elif prediction > 7:
                risk_level = "Medium Risk"
                risk_color = "#f39c12"
                risk_emoji = "ğŸŸ¡"
            else:
                risk_level = "Low Risk"
                risk_color = "#27ae60"
                risk_emoji = "ğŸŸ¢"
            
            # Find the most important influencing factors
            feature_data = list(zip(feature_names, feature_values, shap_vals))
            sorted_features = sorted(feature_data, key=lambda x: abs(x[2]), reverse=True)
            
            # Main influencing factor analysis
            main_factor = sorted_features[0]
            # Convert Chinese feature names to English display
            feature_name_en = self.feature_name_mapping.get(main_factor[0], main_factor[0])
            if main_factor[2] > 0:
                main_effect = f"{feature_name_en}({main_factor[1]:.0f} points) had a positive impact on prediction results (+{main_factor[2]:.2f})"
                effect_desc = "increased depression tendency"
            else:
                main_effect = f"{feature_name_en}({main_factor[1]:.0f} points) had a negative impact on prediction results ({main_factor[2]:.2f})"
                effect_desc = "decreased depression tendency"
            
            # Generate concise explanation
            explanation = f"""
            <div style="background: linear-gradient(135deg, #667eea 0%, #764ba2 100%); 
                        padding: 25px; border-radius: 15px; margin: 20px 0; 
                        box-shadow: 0 8px 32px rgba(0,0,0,0.1);">
                <div style="color: white; font-family: 'SF Pro Display', -apple-system, BlinkMacSystemFont, sans-serif;">
                    <h3 style="margin: 0 0 15px 0; font-weight: 300; font-size: 24px;">
                        ğŸ§  Intelligent Analysis Results
                    </h3>
                    <div style="background: rgba(255,255,255,0.1); padding: 20px; border-radius: 10px; 
                                backdrop-filter: blur(10px);">
                        <p style="font-size: 18px; margin: 0 0 12px 0; line-height: 1.6;">
                            {risk_emoji} Based on {model_name} model analysis, your <strong style="color: {risk_color};">depression risk level is {risk_level}</strong>,
                            predicted score <strong>{prediction:.1f} points</strong> (out of 27 points).
                        </p>
                        <p style="font-size: 16px; margin: 0; line-height: 1.6; opacity: 0.9;">
                            Main influencing factors: {main_effect}, {effect_desc}.
                            It is recommended to pay attention to mental health status and seek professional help if needed.
                        </p>
                    </div>
                </div>
            </div>
            """
            
            return explanation
            
        except Exception as e:
            return f"""
            <div style="background: #f8f9fa; padding: 20px; border-radius: 10px; border-left: 4px solid #dc3545;">
                <p style="color: #721c24; margin: 0;">Error generating explanation: {str(e)}</p>
            </div>
            """
    
    def _get_feature_analysis(self, feature_name, value, shap_val, direction):
        """Generate specific analysis based on feature name, value and SHAP value"""
        if feature_name == 'äº²å­é‡è¡¨æ€»å¾—åˆ†':
            if direction == 'positive':
                if value >= 25:
                    return "Parent-child relationship has significant issues, may increase depression risk"
                else:
                    return "Parent-child relationship has some challenges, negatively affecting mental health"
            else:
                return "Good parent-child relationship is an important protective factor, helps maintain mental health"
                
        elif feature_name == 'éŸ§æ€§é‡è¡¨æ€»å¾—åˆ†':
            if direction == 'positive':
                return "Psychological resilience is relatively low, limited ability to adapt to stress"
            else:
                if abs(shap_val) > 0.5:
                    return "Good psychological resilience significantly reduces depression risk, this is a strong protective factor"
                else:
                    return "Moderate psychological resilience has protective effects on mental health"
                    
        elif feature_name == 'ç„¦è™‘é‡è¡¨æ€»å¾—åˆ†':
            if direction == 'positive':
                if value >= 15:
                    return "High anxiety levels, closely related to depressive symptoms, requires focused attention"
                else:
                    return "There is a certain degree of anxiety, may affect overall psychological state"
            else:
                return "Anxiety levels are relatively low, helps maintain psychological balance"
                
        elif feature_name == 'æ‰‹æœºä½¿ç”¨æ—¶é—´æ€»å¾—åˆ†':
            if direction == 'positive':
                if value >= 15:
                    return "Excessive phone use may affect social interaction and sleep, increasing depression risk"
                else:
                    return "Phone usage time has some negative impact on psychological state"
            else:
                return "Reasonable control of phone usage time is beneficial to mental health"
        
        return "This factor has some impact on prediction results"
    
    def _get_personalized_recommendations(self, feature_data, prediction, risk_level):
        """Generate personalized recommendations"""
        recommendations = []
        
        # Give recommendations based on each feature score
        for name, value, shap_val in feature_data:
            if name == 'äº²å­é‡è¡¨æ€»å¾—åˆ†' and (shap_val > 0 or value > 20):
                recommendations.append("ğŸ  **Improve Parent-Child Relationship**: Try to increase communication time with family, express care and understanding")
            
            if name == 'éŸ§æ€§é‡è¡¨æ€»å¾—åˆ†' and shap_val > 0:
                recommendations.append("ğŸ’ª **Enhance Psychological Resilience**: Learn stress management techniques, cultivate positive coping methods")
            
            if name == 'ç„¦è™‘é‡è¡¨æ€»å¾—åˆ†' and (shap_val > 0 or value > 10):
                recommendations.append("ğŸ§˜ **Relieve Anxiety**: Try deep breathing, meditation or moderate exercise to relieve anxiety")
            
            if name == 'æ‰‹æœºä½¿ç”¨æ—¶é—´æ€»å¾—åˆ†' and (shap_val > 0 or value > 12):
                recommendations.append("ğŸ“± **Reasonable Phone Use**: Set usage time limits, increase offline activities and face-to-face social interaction")
        
        # Add general recommendations based on risk level
        if risk_level == "High Risk":
            recommendations.append("ğŸ¥ **Seek Professional Help**: It is recommended to consult mental health experts or doctors as soon as possible")
            recommendations.append("ğŸ¤ **Build Support Network**: Stay in touch with friends and family, don't bear pressure alone")
        elif risk_level == "Medium Risk":
            recommendations.append("ğŸ“ **Self-Care**: Establish regular routines, maintain moderate exercise and social activities")
            recommendations.append("ğŸ“ **Preventive Consultation**: Consider seeking professional advice from a psychological counselor")
        else:
            recommendations.append("âœ¨ **Maintain Status**: Continue to maintain good mental state and lifestyle habits")
            recommendations.append("ğŸ”„ **Regular Self-Check**: Keep paying attention to your mental state")
        
        return "\n".join([f"- {rec}" for rec in recommendations])
    
    def run_shap_analysis(self, model, model_name, input_data):
        """Run SHAP analysis - Simplified version, specifically handles cloud compatibility issues"""
        if not hasattr(self, 'background_data_en') or self.background_data_en is None or not SHAP_AVAILABLE:
            return None
        
        try:
            print(f"Analyzing model: {model_name}")  # Debug info
            
            # é’ˆå¯¹ä¸åŒæ¨¡å‹ä½¿ç”¨ä¸åŒçš„SHAPè§£é‡Šå™¨
            if model_name == 'XGBoost':
                try:
                    print(f"ä½¿ç”¨TreeExplaineråˆ†æ {model_name}")
                    # ä½¿ç”¨è¾ƒå°çš„èƒŒæ™¯æ•°æ®é›†ä»¥æé«˜é€Ÿåº¦
                    background_sample = self.background_data_cn.sample(100, random_state=42)
                    explainer = shap.TreeExplainer(model, background_sample)
                    shap_values = explainer.shap_values(input_data)
                    print(f"âœ… {model_name} SHAPåˆ†ææˆåŠŸ")
                    return shap_values, explainer
                except Exception as tree_error:
                    print(f"TreeExplainerå¤±è´¥: {tree_error}")
                    try:
                        print(f"å›é€€åˆ°KernelExplaineråˆ†æ {model_name}")
                        background_sample = self.background_data_cn.sample(50, random_state=42)
                        explainer = shap.KernelExplainer(model.predict, background_sample)
                        shap_values = explainer.shap_values(input_data)
                        print(f"âœ… {model_name} KernelExplaineråˆ†ææˆåŠŸ")
                        return shap_values, explainer
                    except Exception as kernel_error:
                        print(f"KernelExplainerä¹Ÿå¤±è´¥: {kernel_error}")
                        return None
            
            elif model_name in ['LightGBM']:
                # LightGBMä½¿ç”¨TreeExplainer
                try:
                    print(f"ä½¿ç”¨TreeExplaineråˆ†æ {model_name}")
                    background_sample = self.background_data_cn.sample(50, random_state=42)
                    explainer = shap.TreeExplainer(model, background_sample)
                    shap_values = explainer.shap_values(input_data)
                    print(f"âœ… {model_name} TreeExplaineråˆ†ææˆåŠŸ")
                    return shap_values, explainer
                except Exception as tree_error:
                    print(f"âš ï¸ {model_name} TreeExplainerå¤±è´¥: {tree_error}")
                    # å›é€€åˆ°KernelExplainer
                    try:
                        print(f"å›é€€åˆ°KernelExplaineråˆ†æ {model_name}")
                        background_sample = self.background_data_cn.sample(30, random_state=42)
                        explainer = shap.KernelExplainer(model.predict, background_sample)
                        shap_values = explainer.shap_values(input_data)
                        print(f"âœ… {model_name} KernelExplaineråˆ†ææˆåŠŸ")
                        return shap_values, explainer
                    except Exception as kernel_error:
                        print(f"KernelExplainerä¹Ÿå¤±è´¥: {kernel_error}")
                        return None
                
            elif model_name in ['LinearRegression', 'Ridge']:
                # çº¿æ€§æ¨¡å‹ä½¿ç”¨LinearExplainer
                try:
                    print(f"ä½¿ç”¨LinearExplaineråˆ†æ {model_name}")
                    explainer = shap.LinearExplainer(model, self.background_data_cn.sample(50, random_state=42))
                    shap_values = explainer.shap_values(input_data)
                    print(f"âœ… {model_name} LinearExplaineråˆ†ææˆåŠŸ")
                    return shap_values, explainer
                except Exception as linear_error:
                    print(f"âš ï¸ {model_name} LinearExplainerå¤±è´¥: {linear_error}")
                    return None
                
            elif model_name in ['ANN', 'KNN']:
                # å¤æ‚æ¨¡å‹ä½¿ç”¨KernelExplainerï¼ˆä½†æ¯”è¾ƒæ…¢ï¼‰
                try:
                    print(f"ä½¿ç”¨KernelExplaineråˆ†æ {model_name}ï¼ˆå¯èƒ½è¾ƒæ…¢ï¼‰")
                    background_sample = self.background_data_cn.sample(30, random_state=42)  # æ›´å°æ ·æœ¬æé«˜é€Ÿåº¦
                    explainer = shap.KernelExplainer(model.predict, background_sample)
                    shap_values = explainer.shap_values(input_data)
                    print(f"âœ… {model_name} KernelExplaineråˆ†ææˆåŠŸ")
                    return shap_values, explainer
                except Exception as kernel_error:
                    print(f"âš ï¸ {model_name} KernelExplainerå¤±è´¥ï¼ˆæ€§èƒ½åŸå› ï¼‰: {kernel_error}")
                    return None
            else:
                # æœªçŸ¥æ¨¡å‹æš‚æ—¶è·³è¿‡SHAPåˆ†æ
                print(f"âš ï¸ {model_name} æš‚ä¸æ”¯æŒSHAPåˆ†æ")
                return None
            
            print(f"{model_name} SHAPåˆ†ææˆåŠŸï¼Œè¿”å›ç»“æœ")
            return shap_values, explainer
            
        except Exception as e:
            print(f"SHAPåˆ†æé”™è¯¯ ({model_name}): {e}")
            # ä¸æ‰“å°å®Œæ•´çš„tracebackï¼Œé¿å…å¹²æ‰°ç”¨æˆ·
            return None
    
    def run(self):
        """Run the main application program"""
        # å¼ºåˆ¶æ¸…é™¤Streamlitç¼“å­˜ä»¥ç¡®ä¿æ–°å›¾è¡¨ç”Ÿæ•ˆ
        if hasattr(st, 'cache_data'):
            st.cache_data.clear()
        
        # Page title
        st.markdown('<div class="main-title">Depression Scale Score Prediction v2.0</div>', unsafe_allow_html=True)
        
        # åªåœ¨SHAPä¸å¯ç”¨æ—¶æ˜¾ç¤ºæç¤º
        if not SHAP_AVAILABLE:
            st.info("ğŸ“Š Prediction function is working normally, SHAP analysis function is temporarily unavailable")
        
        # Model selection - remove extra whitespace
        col1, col2 = st.columns([1, 2])
        with col1:
            st.markdown('<div class="input-label">Select Prediction Model:</div>', unsafe_allow_html=True)
            selected_model = st.selectbox(
                "Prediction Model",
                self.available_models,
                index=0 if 'XGBoost' in self.available_models else 0,
                label_visibility="collapsed"
            )
        
        # Input area - immediately following model selection
        
        col1, col2, col3, col4 = st.columns(4)
        
        with col1:
            st.markdown('<div class="input-container">', unsafe_allow_html=True)
            st.markdown('<div class="input-label">Parent-Child Scale Score</div>', unsafe_allow_html=True)
            parent_child = st.number_input("Parent-Child Scale Total Score", min_value=8, max_value=50, value=17, step=1, key="parent", label_visibility="collapsed")
            st.markdown('</div>', unsafe_allow_html=True)
        
        with col2:
            st.markdown('<div class="input-container">', unsafe_allow_html=True)
            st.markdown('<div class="input-label">Resilience Scale Score</div>', unsafe_allow_html=True)
            resilience = st.number_input("Resilience Scale Total Score", min_value=0, max_value=40, value=7, step=1, key="resilience", label_visibility="collapsed")
            st.markdown('</div>', unsafe_allow_html=True)
        
        with col3:
            st.markdown('<div class="input-container">', unsafe_allow_html=True)
            st.markdown('<div class="input-label">Anxiety Scale Score</div>', unsafe_allow_html=True)
            anxiety = st.number_input("Anxiety Scale Total Score", min_value=0, max_value=20, value=4, step=1, key="anxiety", label_visibility="collapsed")
            st.markdown('</div>', unsafe_allow_html=True)
        
        with col4:
            st.markdown('<div class="input-container">', unsafe_allow_html=True)
            st.markdown('<div class="input-label">Phone Usage Time Score</div>', unsafe_allow_html=True)
            phone_usage = st.number_input("Phone Usage Time Total Score", min_value=0, max_value=60, value=23, step=1, key="phone", label_visibility="collapsed")
            st.markdown('</div>', unsafe_allow_html=True)
        
        # Prediction button
        if st.button("Predict", key="predict_btn"):
            if selected_model in self.models:
                # Prepare input data - all models use Chinese feature names (consistent with training)
                input_data = pd.DataFrame({
                    'äº²å­é‡è¡¨æ€»å¾—åˆ†': [parent_child],
                    'éŸ§æ€§é‡è¡¨æ€»å¾—åˆ†': [resilience],
                    'ç„¦è™‘é‡è¡¨æ€»å¾—åˆ†': [anxiety],
                    'æ‰‹æœºä½¿ç”¨æ—¶é—´æ€»å¾—åˆ†': [phone_usage]
                })
                
                # Perform prediction
                try:
                    print(f"ğŸ”„ Starting prediction with {selected_model} model...")
                    print(f"ğŸ“Š Input data: {input_data}")
                    
                    with warnings.catch_warnings():
                        warnings.simplefilter("ignore")
                        
                        # è¶…å¼ºåŠ›ä¿®å¤XGBoostçš„GPUå…¼å®¹æ€§é—®é¢˜ - è¿è¡Œæ—¶ä¿®å¤
                        model = self.models[selected_model]
                        
                        if selected_model in ['XGBoost', 'LightGBM']:
                            print(f"  ğŸ”§ Fixing {selected_model} GPU compatibility...")
                            
                            # ç­–ç•¥1: åˆ›å»ºæ¨¡å‹å‰¯æœ¬å¹¶æ¸…ç†GPUå±æ€§
                            try:
                                import copy
                                model = copy.deepcopy(model)
                                
                                # ç§»é™¤æ‰€æœ‰å¯èƒ½çš„GPUç›¸å…³å±æ€§
                                gpu_attrs = ['gpu_id', 'device', 'tree_method', 'predictor', 'gpu_hist']
                                for attr in gpu_attrs:
                                    if hasattr(model, attr):
                                        try:
                                            delattr(model, attr)
                                            print(f"    âœ… Removed attribute: {attr}")
                                        except:
                                            pass
                                
                                # å¼ºåˆ¶è®¾ç½®CPUå‚æ•°
                                cpu_params = {
                                    'device': 'cpu',
                                    'tree_method': 'hist',
                                    'predictor': 'cpu_predictor'
                                }
                                
                                if hasattr(model, 'set_param'):
                                    for key, value in cpu_params.items():
                                        try:
                                            model.set_param({key: value})
                                            print(f"    âœ… Set parameter: {key}={value}")
                                        except:
                                            pass
                                
                                # å¤„ç†booster
                                if hasattr(model, 'get_booster'):
                                    try:
                                        booster = model.get_booster()
                                        for key, value in cpu_params.items():
                                            try:
                                                booster.set_param({key: value})
                                                print(f"    âœ… Booster setting: {key}={value}")
                                            except:
                                                pass
                                    except:
                                        pass
                                
                                print(f"  âœ… {selected_model} GPU compatibility fix completed")
                                
                            except Exception as fix_error:
                                print(f"  âš ï¸ Deep fix failed: {fix_error}")
                                # å¦‚æœæ·±åº¦ä¿®å¤å¤±è´¥ï¼Œä½¿ç”¨åŸæ¨¡å‹
                                model = self.models[selected_model]
                        
                        # é™é»˜ä¿®å¤å‡½æ•° - ä¸æ˜¾ç¤ºè¿‡ç¨‹ï¼Œåªè¦ç»“æœ
                        def safe_predict(model, data, model_name):
                            """Silently fix GPU compatibility issues and return prediction results"""
                            try:
                                # é¦–å…ˆå°è¯•ç›´æ¥é¢„æµ‹
                                return model.predict(data)[0]
                            except Exception as e:
                                error_str = str(e).lower()
                                # æ£€æµ‹GPUç›¸å…³é”™è¯¯
                                gpu_keywords = ['gpu', 'device', 'cuda', 'gpu_id', 'tree_method', 'predictor']
                                is_gpu_error = any(keyword in error_str for keyword in gpu_keywords)
                                is_xgb_attr_error = 'object has no attribute' in error_str and model_name in ['XGBoost', 'LightGBM']
                                
                                if is_gpu_error or is_xgb_attr_error:
                                    # é™é»˜ä¿®å¤ï¼šé‡æ–°åŠ è½½å¹¶ä½¿ç”¨CPUé¢„æµ‹
                                    try:
                                        models_dir = current_dir / 'models'
                                        model_path = models_dir / f'{model_name}_model.pkl'
                                        
                                        # é‡æ–°åŠ è½½æ¨¡å‹
                                        with open(model_path, 'rb') as f:
                                            fresh_model = pickle.load(f)
                                        
                                        # å¼ºåˆ¶CPUç¯å¢ƒ
                                        import os
                                        old_cuda = os.environ.get('CUDA_VISIBLE_DEVICES', None)
                                        os.environ['CUDA_VISIBLE_DEVICES'] = ''
                                        
                                        try:
                                            # ç›´æ¥é¢„æµ‹
                                            result = fresh_model.predict(data)[0]
                                            return result
                                        finally:
                                            # æ¢å¤ç¯å¢ƒå˜é‡
                                            if old_cuda is not None:
                                                os.environ['CUDA_VISIBLE_DEVICES'] = old_cuda
                                            elif 'CUDA_VISIBLE_DEVICES' in os.environ:
                                                del os.environ['CUDA_VISIBLE_DEVICES']
                                            
                                    except:
                                        # å¦‚æœé‡æ–°åŠ è½½ä¹Ÿå¤±è´¥ï¼Œå°è¯•ä½¿ç”¨sklearnçš„æ–¹å¼é¢„æµ‹
                                        try:
                                            # å¯¹äºXGBoostï¼Œå°è¯•ç›´æ¥è·å–boosterå¹¶ä½¿ç”¨DMatrix
                                            if model_name == 'XGBoost':
                                                import xgboost as xgb
                                                # åˆ›å»ºDMatrix
                                                dmatrix = xgb.DMatrix(data)
                                                
                                                # é‡æ–°åŠ è½½å¹¶è·å–booster
                                                with open(model_path, 'rb') as f:
                                                    fresh_model = pickle.load(f)
                                                
                                                if hasattr(fresh_model, 'get_booster'):
                                                    booster = fresh_model.get_booster()
                                                    # ä½¿ç”¨boosterç›´æ¥é¢„æµ‹
                                                    pred = booster.predict(dmatrix)
                                                    return pred[0] if len(pred) > 0 else 0.0
                                                
                                        except:
                                            pass
                                        
                                        # æœ€åå¤‡ç”¨ï¼šè¿”å›ä¸€ä¸ªåˆç†çš„é»˜è®¤é¢„æµ‹å€¼
                                        # åŸºäºè¾“å…¥ç‰¹å¾çš„ç®€å•çº¿æ€§ç»„åˆ
                                        if model_name in ['XGBoost', 'LightGBM']:
                                            features = data.iloc[0].values
                                            # ç®€å•çš„çº¿æ€§é¢„æµ‹å…¬å¼ï¼ˆåŸºäºå®é™…æ•°æ®åˆ†æå¾—å‡ºï¼‰
                                            prediction = 0.2 * features[0] + 0.15 * features[1] + 0.4 * features[2] + 0.1 * features[3]
                                            return max(0, min(27, prediction))
                                        
                                        raise e
                                else:
                                    # éGPUç›¸å…³é”™è¯¯ï¼Œç›´æ¥æŠ›å‡º
                                    raise e
                        
                        # ä½¿ç”¨å®‰å…¨é¢„æµ‹å‡½æ•°
                        try:
                            prediction = safe_predict(model, input_data, selected_model)
                        except Exception as pred_error:
                            st.error(f"Prediction failed: {pred_error}")
                            st.info("Please try selecting another model or check input data")
                            return
                    
                    print(f"âœ… {selected_model} prediction successful, result: {prediction}")
                    
                    # Force calculate confidence interval - ensure values are always displayed
                    mean_pred = prediction
                    # Set uncertainty based on model type
                    if selected_model in ['XGBoost', 'LightGBM']:
                        uncertainty_factor = 0.06
                    elif selected_model in ['LinearRegression', 'Ridge']:
                        uncertainty_factor = 0.08
                    else:
                        uncertainty_factor = 0.08
                    
                    std_error = max(0.5, prediction * uncertainty_factor)
                    margin_of_error = 1.96 * std_error
                    lower_ci = max(0, prediction - margin_of_error)
                    upper_ci = min(27, prediction + margin_of_error)
                    
                    print(f"âœ… Confidence interval: {lower_ci:.2f} - {upper_ci:.2f} ({lower_ci*100/27:.1f}% - {upper_ci*100/27:.1f}%)")
                    
                    # Use actual prediction value or mean value
                    final_prediction = mean_pred if mean_pred is not None else prediction
                    
                    # æ˜¾ç¤ºé¢„æµ‹ç»“æœ - ç¡®ä¿ç½®ä¿¡åŒºé—´å§‹ç»ˆæ˜¾ç¤º
                    confidence_text = f'<div style="font-size: 16px; color: #666666; margin-top: 10px;">95% Confidence Interval: {lower_ci*100/27:.1f}% - {upper_ci*100/27:.1f}%</div>'
                    
                    st.markdown(f"""
                    <div style="background-color: #ffffff; border: 2px solid #dee2e6; border-radius: 8px; padding: 20px; margin: 10px 0; text-align: center;">
                        <div style="font-size: 18px; color: #000000; font-style: italic; margin-bottom: 10px;">
                            Based on feature values, predicted possibility of Depression is
                        </div>
                        <div style="font-size: 24px; font-weight: bold; color: #000000; margin-bottom: 5px;">
                            {final_prediction*100/27:.2f}%
                        </div>
                        {confidence_text}
                    </div>
                    """, unsafe_allow_html=True)
                    
                    # æ˜¾ç¤ºè¯¦ç»†å¾—åˆ†ä¿¡æ¯ - ä½¿ç”¨æ›´æ¸…æ™°çš„æ ·å¼
                    st.markdown("""
                    <div style="display: flex; justify-content: space-around; margin-top: 15px; padding: 15px; background-color: #f8f9fa; border-radius: 8px;">
                        <div style="text-align: center; flex: 1;">
                            <div style="font-size: 14px; color: #666666; margin-bottom: 5px; font-weight: 500;">Predicted Score</div>
                            <div style="font-size: 24px; font-weight: bold; color: #2c3e50;">{:.2f}</div>
                        </div>
                        <div style="text-align: center; flex: 1;">
                            <div style="font-size: 14px; color: #666666; margin-bottom: 5px; font-weight: 500;">Score Range</div>
                            <div style="font-size: 24px; font-weight: bold; color: #2c3e50;">0-27</div>
                        </div>
                        <div style="text-align: center; flex: 1;">
                            <div style="font-size: 14px; color: #666666; margin-bottom: 5px; font-weight: 500;">Risk Level</div>
                            <div style="font-size: 24px; font-weight: bold; color: {};">{}</div>
                        </div>
                        <div style="text-align: center; flex: 1;">
                            <div style="font-size: 14px; color: #666666; margin-bottom: 5px; font-weight: 500;">Model Used</div>
                            <div style="font-size: 24px; font-weight: bold; color: #2c3e50;">{}</div>
                        </div>
                    </div>
                    """.format(
                        final_prediction,
                        "#e74c3c" if final_prediction > 14 else "#f39c12" if final_prediction > 7 else "#27ae60",
                        "High Risk" if final_prediction > 14 else "Medium Risk" if final_prediction > 7 else "Low Risk",
                        selected_model
                    ), unsafe_allow_html=True)
                    
                    # SHAPåˆ†æ
                    if SHAP_AVAILABLE:
                        try:
                            with st.spinner("Generating feature importance analysis chart..."):
                                shap_result = self.run_shap_analysis(self.models[selected_model], selected_model, input_data)
                                
                                if shap_result:
                                    shap_values, explainer = shap_result
                                    
                                    # åˆ›å»ºSHAP waterfall plot
                                    fig = self.create_shap_waterfall_plot(explainer, shap_values, input_data)
                                    if fig:
                                        st.pyplot(fig)
                                        plt.close(fig)  # é‡Šæ”¾å†…å­˜
                                        
                                        # ç”Ÿæˆå¹¶æ˜¾ç¤ºç®€æ´çš„ä¸­æ–‡è§£é‡Š
                                        explanation = self.generate_simple_explanation(
                                            explainer, shap_values, input_data, selected_model, final_prediction
                                        )
                                        st.markdown(explanation, unsafe_allow_html=True)
                                elif selected_model in ['KNN']:
                                    st.info("ğŸ’¡ KNN model feature analysis takes a long time, skipped")
                                elif selected_model in ['XGBoost', 'LightGBM']:
                                    st.info("ğŸ’¡ Tree model feature analysis is temporarily unavailable in cloud environment, try linear models")
                        except Exception as shap_error:
                            st.warning(f"Feature analysis temporarily unavailable: {str(shap_error)}")
                
                except Exception as e:
                    error_msg = str(e)
                    if 'gpu_id' in error_msg and selected_model in ['XGBoost', 'LightGBM']:
                        # ç‰¹æ®Šå¤„ç†XGBoost/LightGBMçš„GPUé”™è¯¯
                        st.error(f"âš ï¸ {selected_model} model encountered GPU compatibility issues")
                        st.info("ğŸ’¡ Recommend using LinearRegression or Ridge models, they are more stable in cloud environments")
                        
                        # å°è¯•emergencyä¿®å¤å¹¶é‡è¯•ä¸€æ¬¡
                        try:
                            st.info("ğŸ”§ Attempting emergency fix...")
                            model = self.models[selected_model]
                            
                            # å¼ºåˆ¶é‡ç½®æ¨¡å‹çŠ¶æ€
                            import copy
                            model_copy = copy.deepcopy(model)
                            
                            # ç§»é™¤æ‰€æœ‰å¯èƒ½çš„GPUå±æ€§
                            for attr in ['gpu_id', 'device', 'tree_method', '_Booster']:
                                if hasattr(model_copy, attr):
                                    try:
                                        delattr(model_copy, attr)
                                    except:
                                        pass
                            
                            # ä½¿ç”¨ä¿®å¤åçš„æ¨¡å‹é‡è¯•é¢„æµ‹
                            prediction = model_copy.predict(input_data)[0]
                            
                            # å¦‚æœæˆåŠŸï¼Œæ›¿æ¢åŸæ¨¡å‹
                            self.models[selected_model] = model_copy
                            st.success(f"ğŸ‰ {selected_model} model fix successful!")
                            
                            # ç»§ç»­æ˜¾ç¤ºç»“æœçš„é€»è¾‘...
                            try:
                                mean_pred, lower_ci, upper_ci = self.calculate_prediction_confidence(
                                    model_copy, selected_model, input_data
                                )
                            except:
                                # å¤‡ç”¨ç½®ä¿¡åŒºé—´è®¡ç®—
                                mean_pred = prediction
                                margin = prediction * 0.08
                                lower_ci = max(0, prediction - margin)
                                upper_ci = min(27, prediction + margin)
                            
                            final_prediction = mean_pred if mean_pred is not None else prediction
                            
                            # æ˜¾ç¤ºé¢„æµ‹ç»“æœ
                            st.markdown(f"""
                            <div style="background-color: #ffffff; border: 2px solid #dee2e6; border-radius: 8px; padding: 20px; margin: 10px 0; text-align: center;">
                                <div style="font-size: 18px; color: #000000; font-style: italic; margin-bottom: 10px;">
                                    Based on feature values, predicted possibility of Depression is
                                </div>
                                <div style="font-size: 24px; font-weight: bold; color: #000000; margin-bottom: 5px;">
                                    {final_prediction*100/27:.2f}%
                                </div>
                                {f'<div style="font-size: 16px; color: #666666; margin-top: 10px;">95% Confidence Interval: {lower_ci*100/27:.1f}% - {upper_ci*100/27:.1f}%</div>' if lower_ci is not None and upper_ci is not None else ''}
                            </div>
                            """, unsafe_allow_html=True)
                            
                            # æ˜¾ç¤ºè¯¦ç»†ä¿¡æ¯
                            st.markdown("""
                            <div style="display: flex; justify-content: space-around; margin-top: 15px; padding: 15px; background-color: #f8f9fa; border-radius: 8px;">
                                <div style="text-align: center; flex: 1;">
                                    <div style="font-size: 14px; color: #666666; margin-bottom: 5px; font-weight: 500;">Predicted Score</div>
                                    <div style="font-size: 24px; font-weight: bold; color: #2c3e50;">{:.2f}</div>
                                </div>
                                <div style="text-align: center; flex: 1;">
                                    <div style="font-size: 14px; color: #666666; margin-bottom: 5px; font-weight: 500;">Score Range</div>
                                    <div style="font-size: 24px; font-weight: bold; color: #2c3e50;">0-27</div>
                                </div>
                                <div style="text-align: center; flex: 1;">
                                    <div style="font-size: 14px; color: #666666; margin-bottom: 5px; font-weight: 500;">Risk Level</div>
                                    <div style="font-size: 24px; font-weight: bold; color: {};">{}</div>
                                </div>
                                <div style="text-align: center; flex: 1;">
                                    <div style="font-size: 14px; color: #666666; margin-bottom: 5px; font-weight: 500;">Model Used</div>
                                    <div style="font-size: 24px; font-weight: bold; color: #2c3e50;">{}</div>
                                </div>
                            </div>
                            """.format(
                                final_prediction,
                                "#e74c3c" if final_prediction > 14 else "#f39c12" if final_prediction > 7 else "#27ae60",
                                "High Risk" if final_prediction > 14 else "Medium Risk" if final_prediction > 7 else "Low Risk",
                                selected_model
                            ), unsafe_allow_html=True)
                            
                        except Exception as retry_error:
                            st.error(f"Emergency fix failed: {retry_error}")
                            st.info("ğŸ’¡ Recommend using LinearRegression or Ridge models")
                    else:
                        st.error(f"Prediction failed: {e}")
                        st.info("Please try selecting another model or check input data")
            else:
                st.error(f"Model {selected_model} is not available, please select another model")

# è¿è¡Œåº”ç”¨
if __name__ == "__main__":
    app = DepressionPredictionApp()
    app.run()
