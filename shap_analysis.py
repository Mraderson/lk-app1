#!/usr/bin/env python
# -*- coding: utf-8 -*-

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import shap
import os
import warnings
from sklearn.ensemble import RandomForestRegressor
import xgboost as xgb
import lightgbm as lgb
from utils import ensure_dir

# å¯¼å…¥GPUä¼˜åŒ–é…ç½®
try:
    from gpu_shap_config import get_gpu_shap_config, monitor_gpu_usage
    GPU_AVAILABLE = True
except ImportError:
    print("âš ï¸ GPUé…ç½®æ¨¡å—æœªæ‰¾åˆ°ï¼Œä½¿ç”¨é»˜è®¤è®¾ç½®")
    GPU_AVAILABLE = False

# å¿½ç•¥SHAPç›¸å…³è­¦å‘Š
warnings.filterwarnings("ignore", category=FutureWarning, module="shap")
warnings.filterwarnings("ignore", category=UserWarning, module="shap")

# è®¾ç½®matplotlibä¸­æ–‡å­—ä½“
plt.rcParams['font.sans-serif'] = ['DejaVu Sans', 'Bitstream Vera Sans', 'Computer Modern Sans Serif', 'Lucida Grande', 'Verdana', 'Geneva', 'Lucid', 'Helvetica', 'Avant Garde', 'sans-serif']
plt.rcParams['axes.unicode_minus'] = True

class SHAPAnalyzer:
    """SHAPåˆ†æå™¨ç±»ï¼Œæä¾›å®Œæ•´çš„SHAPå¯è§£é‡Šæ€§åˆ†æåŠŸèƒ½"""
    
    def __init__(self, model, X_train, X_test, feature_names=None, model_name="Model", use_gpu=True):
        """
        åˆå§‹åŒ–SHAPåˆ†æå™¨
        
        Parameters:
        -----------
        model : sklearn model or xgboost/lightgbm model
            è®­ç»ƒå¥½çš„æ¨¡å‹
        X_train : array-like
            è®­ç»ƒæ•°æ®ç‰¹å¾
        X_test : array-like
            æµ‹è¯•æ•°æ®ç‰¹å¾
        feature_names : list, optional
            ç‰¹å¾åç§°åˆ—è¡¨
        model_name : str, default="Model"
            æ¨¡å‹åç§°
        use_gpu : bool, default=True
            æ˜¯å¦ä½¿ç”¨GPUåŠ é€ŸSHAPè®¡ç®—
        """
        self.model = model
        self.X_train = X_train
        self.X_test = X_test
        self.model_name = model_name
        self.use_gpu = use_gpu and GPU_AVAILABLE
        
        # è·å–GPUä¼˜åŒ–é…ç½®
        if self.use_gpu:
            # ç¡®å®šæ¨¡å‹ç±»å‹
            if isinstance(model, (xgb.XGBRegressor, xgb.XGBClassifier, lgb.LGBMRegressor, lgb.LGBMClassifier)) or \
               hasattr(model, 'tree_') or hasattr(model, 'estimators_'):
                self.gpu_config = get_gpu_shap_config('tree')
                self.model_type = 'tree'
            else:
                self.gpu_config = get_gpu_shap_config('kernel')
                self.model_type = 'kernel'
            
            print(f"ğŸš€ {model_name}æ¨¡å‹å¯ç”¨GPUåŠ é€ŸSHAPåˆ†æ")
            print(f"ğŸ“Š æ‰¹æ¬¡å¤§å°: {self.gpu_config['batch_size']}")
        else:
            self.gpu_config = {'batch_size': 100, 'use_gpu': False}
            self.model_type = 'auto'
            print(f"ğŸ’» {model_name}æ¨¡å‹ä½¿ç”¨CPUè¿›è¡ŒSHAPåˆ†æ")
        
        # è®¾ç½®ç‰¹å¾åç§°
        if feature_names is None:
            self.feature_names = [f'Feature_{i}' for i in range(X_train.shape[1])]
        else:
            self.feature_names = feature_names
        
        # ä¸­è‹±æ–‡ç‰¹å¾åç§°æ˜ å°„
        self.feature_name_mapping = {
            'äº²å­é‡è¡¨æ€»å¾—åˆ†': 'Parent-Child Relationship',
            'éŸ§æ€§é‡è¡¨æ€»å¾—åˆ†': 'Resilience', 
            'ç„¦è™‘é‡è¡¨æ€»å¾—åˆ†': 'Anxiety',
            'æ‰‹æœºä½¿ç”¨æ—¶é—´æ€»å¾—åˆ†': 'Phone Usage Time'
        }
        
        # è½¬æ¢ä¸ºè‹±æ–‡ç‰¹å¾å
        self.english_feature_names = [
            self.feature_name_mapping.get(name, name) for name in self.feature_names
        ]
        
        # ç¡®ä¿ç»“æœç›®å½•å­˜åœ¨
        self.save_dir = f'results/{model_name}/shap_analysis'
        ensure_dir(self.save_dir)
        
        # åˆå§‹åŒ–explainer
        self.explainer = None
        self.shap_values = None
        
    def _initialize_explainer(self):
        """åˆå§‹åŒ–SHAPè§£é‡Šå™¨"""
        print(f"æ­£åœ¨ä¸º{self.model_name}æ¨¡å‹åˆå§‹åŒ–SHAPè§£é‡Šå™¨...")
        
        try:
            # æ ¹æ®æ¨¡å‹ç±»å‹é€‰æ‹©åˆé€‚çš„è§£é‡Šå™¨
            if isinstance(self.model, (xgb.XGBRegressor, xgb.XGBClassifier)):
                print("ä½¿ç”¨TreeExplainer for XGBoost...")
                self.explainer = shap.TreeExplainer(self.model)
                
            elif isinstance(self.model, (lgb.LGBMRegressor, lgb.LGBMClassifier)):
                print("ä½¿ç”¨TreeExplainer for LightGBM...")
                self.explainer = shap.TreeExplainer(self.model)
                
            elif hasattr(self.model, 'tree_') or hasattr(self.model, 'estimators_'):
                # éšæœºæ£®æ—ã€å†³ç­–æ ‘ç­‰åŸºäºæ ‘çš„æ¨¡å‹
                print("ä½¿ç”¨TreeExplainer for tree-based model...")
                self.explainer = shap.TreeExplainer(self.model)
                
            else:
                # å…¶ä»–æ¨¡å‹ä½¿ç”¨KernelExplainer
                print("ä½¿ç”¨KernelExplainer for general model...")
                # ä½¿ç”¨è®­ç»ƒæ•°æ®çš„å­é›†ä½œä¸ºèƒŒæ™¯æ•°æ®ä»¥åŠ å¿«è®¡ç®—
                background_size = min(100, len(self.X_train))
                background_indices = np.random.choice(len(self.X_train), background_size, replace=False)
                background_data = self.X_train[background_indices]
                self.explainer = shap.KernelExplainer(self.model.predict, background_data)
                
        except Exception as e:
            print(f"åˆå§‹åŒ–TreeExplainerå¤±è´¥: {str(e)}")
            print("å›é€€åˆ°KernelExplainer...")
            # å›é€€åˆ°KernelExplainer
            background_size = min(50, len(self.X_train))
            background_indices = np.random.choice(len(self.X_train), background_size, replace=False)
            background_data = self.X_train[background_indices]
            self.explainer = shap.KernelExplainer(self.model.predict, background_data)
    
    def calculate_shap_values(self, max_samples=None):
        """è®¡ç®—SHAPå€¼"""
        if self.explainer is None:
            self._initialize_explainer()
        
        print(f"æ­£åœ¨è®¡ç®—{self.model_name}æ¨¡å‹çš„SHAPå€¼...")
        
        # æ™ºèƒ½æ ·æœ¬æ•°é‡é€‰æ‹©
        if max_samples is None:
            max_samples = self._get_optimal_sample_size()
        
        # ç¡®ä¿ä¸è¶…è¿‡æµ‹è¯•é›†å¤§å°
        max_samples = min(max_samples, len(self.X_test))
        
        if len(self.X_test) > max_samples:
            print(f"æ•°æ®é›†å¤§å°: {len(self.X_test)}, é€‰æ‹©{max_samples}ä¸ªæ ·æœ¬è¿›è¡ŒSHAPåˆ†æ...")
            print(f"ğŸ’¡ æ ·æœ¬é€‰æ‹©ç­–ç•¥: {'GPUåŠ é€Ÿ' if self.use_gpu else 'CPUè®¡ç®—'} + {self.model_type}æ¨¡å‹")
            indices = np.random.choice(len(self.X_test), max_samples, replace=False)
            X_test_sample = self.X_test[indices]
        else:
            print(f"ä½¿ç”¨å…¨éƒ¨{len(self.X_test)}ä¸ªæµ‹è¯•æ ·æœ¬è¿›è¡ŒSHAPåˆ†æ")
            X_test_sample = self.X_test
            indices = np.arange(len(self.X_test))
        
        try:
            # è®¡ç®—SHAPå€¼
            if isinstance(self.explainer, shap.TreeExplainer):
                # TreeExplaineré€šå¸¸æ›´å¿«
                self.shap_values = self.explainer.shap_values(X_test_sample)
            else:
                # KernelExplainerå¯èƒ½è¾ƒæ…¢
                print("ä½¿ç”¨KernelExplainerè®¡ç®—SHAPå€¼ï¼Œè¿™å¯èƒ½éœ€è¦ä¸€äº›æ—¶é—´...")
                self.shap_values = self.explainer.shap_values(X_test_sample)
            
            # ä¿å­˜ç”¨äºåˆ†æçš„æ•°æ®
            self.X_test_sample = X_test_sample
            self.sample_indices = indices
            
            print(f"SHAPå€¼è®¡ç®—å®Œæˆï¼å½¢çŠ¶: {self.shap_values.shape}")
            
        except Exception as e:
            print(f"è®¡ç®—SHAPå€¼æ—¶å‘ç”Ÿé”™è¯¯: {str(e)}")
            return False
            
        return True
    
    def _get_optimal_sample_size(self, research_mode='fine'):
        """æ ¹æ®æ¡ä»¶æ™ºèƒ½é€‰æ‹©æœ€ä¼˜æ ·æœ¬æ•°é‡
        
        Parameters:
        -----------
        research_mode : str
            ç ”ç©¶æ¨¡å¼: 'fast'(å¿«é€Ÿ), 'balanced'(å¹³è¡¡), 'fine'(ç²¾ç»†), 'deep'(æ·±åº¦)
        """
        dataset_size = len(self.X_test)
        
        # ç‰¹æ®Šæ¨¡å‹ä¼˜åŒ–ï¼šSVM/ANNç­‰ä½¿ç”¨KernelExplainerçš„æ¨¡å‹
        model_name_lower = self.model_name.lower()
        is_slow_model = any(name in model_name_lower for name in ['svm', 'ann', 'neural', 'mlp'])
        
        if is_slow_model:
            print(f"ğŸŒ æ£€æµ‹åˆ°{self.model_name}æ¨¡å‹ï¼Œä½¿ç”¨KernelExplainerä¸“ç”¨ä¼˜åŒ–...")
            
            # å¯¹äºSVMç­‰æ…¢é€Ÿæ¨¡å‹ï¼Œå¤§å¹…å‡å°‘æ ·æœ¬æ•°é‡
            if research_mode == 'fast':
                recommended = min(200, max(100, dataset_size // 100))
            elif research_mode == 'balanced':
                recommended = min(500, max(200, dataset_size // 50))
            elif research_mode == 'fine':
                recommended = min(800, max(400, dataset_size // 25))
                print(f"ğŸ“Š SVMç²¾ç»†æ¨¡å¼ä¼˜åŒ–ï¼šä½¿ç”¨{recommended}æ ·æœ¬ï¼Œå¹³è¡¡è´¨é‡ä¸æ•ˆç‡")
            elif research_mode == 'deep':
                recommended = min(1200, max(600, dataset_size // 20))
            else:
                recommended = min(400, max(200, dataset_size // 50))
            
            print(f"âš¡ SVMä¼˜åŒ–ç­–ç•¥ï¼šä½¿ç”¨{recommended}æ ·æœ¬æ›¿ä»£5000æ ·æœ¬")
            print(f"ğŸ“ˆ é¢„è®¡æ—¶é—´ä»4.5å°æ—¶ç¼©çŸ­è‡³15-30åˆ†é’Ÿ")
            
        else:
            # 4090 GPUä¸“é¡¹ä¼˜åŒ–é…ç½®ï¼ˆéSVMæ¨¡å‹ï¼‰
            if self.use_gpu:
                print("ğŸš€ æ£€æµ‹åˆ°GPUæ¨¡å¼ï¼Œé’ˆå¯¹é«˜æ€§èƒ½GPUè¿›è¡Œä¼˜åŒ–...")
                
                if research_mode == 'fast':
                    # å¿«é€Ÿæ¨¡å¼ï¼šå¹³è¡¡é€Ÿåº¦å’Œè´¨é‡
                    recommended = min(2000, max(800, dataset_size // 10))
                elif research_mode == 'balanced':
                    # å¹³è¡¡æ¨¡å¼ï¼šä¸­ç­‰ç²¾åº¦
                    recommended = min(3500, max(1500, dataset_size // 6))
                elif research_mode == 'fine':
                    # ç²¾ç»†æ¨¡å¼ï¼šé«˜è´¨é‡åˆ†æï¼ˆä¸“ä¸ºæ‚¨çš„ç ”ç©¶ä¼˜åŒ–ï¼‰
                    recommended = min(5000, max(2500, dataset_size // 4))
                    print("ğŸ“Š ä½¿ç”¨ç²¾ç»†ç ”ç©¶é…ç½®ï¼š5000æ ·æœ¬ï¼Œç¡®ä¿é«˜è´¨é‡SHAPåˆ†æ")
                elif research_mode == 'deep':
                    # æ·±åº¦æ¨¡å¼ï¼šæœ€é«˜ç²¾åº¦
                    recommended = min(8000, max(4000, dataset_size // 3))
                else:
                    recommended = min(3000, max(1200, dataset_size // 8))
            else:
                print("ğŸ’» CPUæ¨¡å¼æ£€æµ‹ï¼Œä½¿ç”¨ä¿å®ˆé…ç½®...")
                # CPUæ¨¡å¼ä¿æŒåŸæœ‰é€»è¾‘
                if research_mode == 'fast':
                    recommended = min(800, max(300, dataset_size // 25))
                elif research_mode == 'balanced':
                    recommended = min(1500, max(600, dataset_size // 15))
                elif research_mode == 'fine':
                    recommended = min(2500, max(1200, dataset_size // 10))
                elif research_mode == 'deep':
                    recommended = min(4000, max(2000, dataset_size // 8))
                else:
                    recommended = min(1200, max(500, dataset_size // 20))
        
        # ç¡®ä¿ä¸è¶…è¿‡æ•°æ®é›†å¤§å°
        recommended = min(recommended, dataset_size)
        
        # æ€§èƒ½ç­‰çº§æ ‡è¯†
        if recommended <= 500:
            level = "å¿«é€Ÿ"
            precision_boost = "200-300%"
        elif recommended <= 1200:
            level = "å¹³è¡¡" 
            precision_boost = "400-600%"
        elif recommended <= 3000:
            level = "ç²¾ç»†"
            precision_boost = "800-1200%"
        else:
            level = "æ·±åº¦"
            precision_boost = "1500%+"
        
        print(f"ğŸ“Š æ™ºèƒ½æ¨èæ ·æœ¬æ•°é‡: {recommended:,} ({level}åˆ†æ - {research_mode.upper()}æ¨¡å¼)")
        print(f"ğŸ”§ é…ç½®è¯¦æƒ…: {'GPUåŠ é€Ÿæ¨¡å¼' if self.use_gpu else 'CPUè®¡ç®—æ¨¡å¼'}")
        
        # æ ¹æ®æ¨¡å‹ç±»å‹ç»™å‡ºç²¾ç¡®æ—¶é—´é¢„ä¼°
        if is_slow_model:
            # SVM/ANNç­‰æ…¢é€Ÿæ¨¡å‹çš„æ—¶é—´é¢„ä¼°
            if recommended <= 200:
                time_est = "5-10åˆ†é’Ÿ"
            elif recommended <= 500:
                time_est = "10-20åˆ†é’Ÿ"
            elif recommended <= 800:
                time_est = "15-35åˆ†é’Ÿ"
            elif recommended <= 1200:
                time_est = "25-50åˆ†é’Ÿ"
            else:
                time_est = "45åˆ†é’Ÿ-1.5å°æ—¶"
        else:
            # GPUæ¨¡å¼çš„ç²¾ç¡®æ—¶é—´é¢„ä¼°ï¼ˆåŸºäº4090æ€§èƒ½ï¼‰
            if self.use_gpu:
                if recommended <= 1000:
                    time_est = "2-5åˆ†é’Ÿ"
                elif recommended <= 2500:
                    time_est = "5-12åˆ†é’Ÿ"
                elif recommended <= 5000:
                    time_est = "8-20åˆ†é’Ÿ"
                elif recommended <= 8000:
                    time_est = "15-35åˆ†é’Ÿ"
                else:
                    time_est = "30åˆ†é’Ÿ-1å°æ—¶"
            else:
                if recommended <= 800:
                    time_est = "5-15åˆ†é’Ÿ"
                elif recommended <= 2000:
                    time_est = "15-45åˆ†é’Ÿ"
                elif recommended <= 4000:
                    time_est = "45åˆ†é’Ÿ-2å°æ—¶"
                else:
                    time_est = "2-5å°æ—¶"
        
        print(f"â±ï¸  é¢„è®¡è€—æ—¶: {time_est}")
        print(f"ğŸ“ˆ åˆ†æç²¾åº¦æå‡: ç›¸æ¯”åŸºç¡€æ¨¡å¼æå‡ {precision_boost}")
        
        # ä¸ºç²¾ç»†ç ”ç©¶æä¾›è¯¦ç»†ä¿¡æ¯
        if research_mode in ['fine', 'deep'] and not is_slow_model:
            print(f"ğŸ”¬ {research_mode.upper()}ç ”ç©¶æ¨¡å¼ç‰¹ç‚¹:")
            if research_mode == 'fine':
                print("   â€¢ 5000æ ·æœ¬ç¡®ä¿ç»Ÿè®¡ç¨³å®šæ€§")
                print("   â€¢ å æµ‹è¯•é›†25%ï¼Œä»£è¡¨æ€§å……è¶³") 
                print("   â€¢ é€‚åˆå­¦æœ¯ç ”ç©¶å’Œæ¨¡å‹æ¯”è¾ƒ")
                print("   â€¢ GPUä¼˜åŒ–ï¼Œé«˜æ•ˆå®Œæˆåˆ†æ")
            else:
                print("   â€¢ 8000æ ·æœ¬æä¾›æœ€é«˜ç²¾åº¦")
                print("   â€¢ é€‚åˆé¡¶çº§æœŸåˆŠå‘è¡¨")
                print("   â€¢ æ·±åº¦ç‰¹å¾äº¤äº’åˆ†æ")
                print("   â€¢ æœ€ç¨³å®šçš„SHAPå€¼ä¼°è®¡")
        elif is_slow_model:
            print(f"ğŸ”¬ {self.model_name}æ¨¡å‹ä¼˜åŒ–ç‰¹ç‚¹:")
            print(f"   â€¢ é’ˆå¯¹KernelExplainerä¼˜åŒ–çš„æ ·æœ¬æ•°é‡")
            print(f"   â€¢ å¹³è¡¡åˆ†æè´¨é‡ä¸è®¡ç®—æ•ˆç‡")
            print(f"   â€¢ ç¡®ä¿åˆç†çš„åˆ†ææ—¶é—´")
            print(f"   â€¢ æä¾›å¯è§£é‡Šä½†é«˜æ•ˆçš„ç»“æœ")
        
        return recommended
    
    def plot_summary_plot(self, plot_type='dot', max_display=10):
        """ç»˜åˆ¶SHAPæ‘˜è¦å›¾"""
        if self.shap_values is None:
            print("è¯·å…ˆè®¡ç®—SHAPå€¼ï¼")
            return
        
        print(f"æ­£åœ¨ç”Ÿæˆ{self.model_name}æ¨¡å‹çš„SHAPæ‘˜è¦å›¾...")
        
        # è®¾ç½®å›¾å½¢å¤§å°
        plt.figure(figsize=(12, 8))
        
        try:
            # ç»˜åˆ¶æ‘˜è¦å›¾
            shap.summary_plot(
                self.shap_values, 
                self.X_test_sample,
                feature_names=self.english_feature_names,
                plot_type=plot_type,
                max_display=max_display,
                show=False
            )
            
            plt.title(f'{self.model_name} SHAP Summary Plot', fontsize=16, pad=20)
            plt.tight_layout()
            
            # ä¿å­˜å›¾ç‰‡
            save_path = os.path.join(self.save_dir, f'shap_summary_{plot_type}.png')
            plt.savefig(save_path, dpi=300, bbox_inches='tight')
            plt.close()
            
            print(f"SHAPæ‘˜è¦å›¾å·²ä¿å­˜åˆ°: {save_path}")
            
        except Exception as e:
            print(f"ç»˜åˆ¶SHAPæ‘˜è¦å›¾æ—¶å‘ç”Ÿé”™è¯¯: {str(e)}")
            plt.close()
    
    def plot_beeswarm_plot(self, max_display=10):
        """ç»˜åˆ¶SHAPèœ‚ç¾¤å›¾ï¼ˆç‰¹å¾å¯†åº¦æ•£ç‚¹å›¾ï¼‰"""
        if self.shap_values is None:
            print("è¯·å…ˆè®¡ç®—SHAPå€¼ï¼")
            return
        
        print(f"æ­£åœ¨ç”Ÿæˆ{self.model_name}æ¨¡å‹çš„SHAPèœ‚ç¾¤å›¾...")
        
        # è®¾ç½®å›¾å½¢å¤§å°
        plt.figure(figsize=(12, 8))
        
        try:
            # ç»˜åˆ¶èœ‚ç¾¤å›¾
            shap.plots.beeswarm(
                shap.Explanation(
                    values=self.shap_values,
                    data=self.X_test_sample,
                    feature_names=self.english_feature_names
                ),
                max_display=max_display,
                show=False
            )
            
            plt.title(f'{self.model_name} SHAP Beeswarm Plot', fontsize=16, pad=20)
            plt.tight_layout()
            
            # ä¿å­˜å›¾ç‰‡
            save_path = os.path.join(self.save_dir, 'shap_beeswarm.png')
            plt.savefig(save_path, dpi=300, bbox_inches='tight')
            plt.close()
            
            print(f"SHAPèœ‚ç¾¤å›¾å·²ä¿å­˜åˆ°: {save_path}")
            
        except Exception as e:
            print(f"ç»˜åˆ¶SHAPèœ‚ç¾¤å›¾æ—¶å‘ç”Ÿé”™è¯¯: {str(e)}")
            # å›é€€åˆ°ä¼ ç»Ÿçš„summary plot
            print("å›é€€åˆ°ä¼ ç»Ÿçš„summary plot...")
            self.plot_summary_plot(plot_type='dot', max_display=max_display)
    
    def plot_dependence_plots(self, features=None):
        """ç»˜åˆ¶SHAPä¾èµ–å›¾"""
        if self.shap_values is None:
            print("è¯·å…ˆè®¡ç®—SHAPå€¼ï¼")
            return
        
        print(f"æ­£åœ¨ç”Ÿæˆ{self.model_name}æ¨¡å‹çš„SHAPä¾èµ–å›¾...")
        
        # å¦‚æœæ²¡æœ‰æŒ‡å®šç‰¹å¾ï¼Œåˆ™ä¸ºæ‰€æœ‰ç‰¹å¾ç»˜åˆ¶ä¾èµ–å›¾
        if features is None:
            features = list(range(len(self.english_feature_names)))
        elif isinstance(features, (list, tuple)) and all(isinstance(f, str) for f in features):
            # å¦‚æœä¼ å…¥çš„æ˜¯ç‰¹å¾åç§°ï¼Œè½¬æ¢ä¸ºç´¢å¼•
            features = [self.english_feature_names.index(f) for f in features if f in self.english_feature_names]
        
        for feature_idx in features:
            if feature_idx >= len(self.english_feature_names):
                continue
                
            feature_name = self.english_feature_names[feature_idx]
            
            try:
                # è®¾ç½®å›¾å½¢å¤§å°
                plt.figure(figsize=(10, 6))
                
                # ç»˜åˆ¶ä¾èµ–å›¾
                shap.dependence_plot(
                    feature_idx,
                    self.shap_values,
                    self.X_test_sample,
                    feature_names=self.english_feature_names,
                    show=False
                )
                
                plt.title(f'{self.model_name} SHAP Dependence Plot - {feature_name}', fontsize=14, pad=20)
                plt.tight_layout()
                
                # ä¿å­˜å›¾ç‰‡
                safe_feature_name = feature_name.replace(' ', '_').replace('-', '_')
                save_path = os.path.join(self.save_dir, f'shap_dependence_{safe_feature_name}.png')
                plt.savefig(save_path, dpi=300, bbox_inches='tight')
                plt.close()
                
                print(f"SHAPä¾èµ–å›¾({feature_name})å·²ä¿å­˜åˆ°: {save_path}")
                
            except Exception as e:
                print(f"ç»˜åˆ¶ç‰¹å¾ {feature_name} çš„SHAPä¾èµ–å›¾æ—¶å‘ç”Ÿé”™è¯¯: {str(e)}")
                plt.close()
                continue
    
    def plot_waterfall_plot(self, sample_idx=0):
        """ç»˜åˆ¶SHAPç€‘å¸ƒå›¾ï¼ˆå•ä¸ªæ ·æœ¬çš„è§£é‡Šï¼‰"""
        if self.shap_values is None:
            print("è¯·å…ˆè®¡ç®—SHAPå€¼ï¼")
            return
        
        if sample_idx >= len(self.shap_values):
            print(f"æ ·æœ¬ç´¢å¼• {sample_idx} è¶…å‡ºèŒƒå›´ï¼")
            return
        
        print(f"æ­£åœ¨ç”Ÿæˆ{self.model_name}æ¨¡å‹çš„SHAPç€‘å¸ƒå›¾ï¼ˆæ ·æœ¬ {sample_idx}ï¼‰...")
        
        try:
            # è®¾ç½®å›¾å½¢å¤§å°
            plt.figure(figsize=(12, 8))
            
            # åˆ›å»ºExplanationå¯¹è±¡
            explanation = shap.Explanation(
                values=self.shap_values[sample_idx],
                base_values=self.explainer.expected_value if hasattr(self.explainer, 'expected_value') else 0,
                data=self.X_test_sample[sample_idx],
                feature_names=self.english_feature_names
            )
            
            # ç»˜åˆ¶ç€‘å¸ƒå›¾
            shap.plots.waterfall(explanation, show=False)
            
            plt.title(f'{self.model_name} SHAP Waterfall Plot - Sample {sample_idx}', fontsize=14, pad=20)
            plt.tight_layout()
            
            # ä¿å­˜å›¾ç‰‡
            save_path = os.path.join(self.save_dir, f'shap_waterfall_sample_{sample_idx}.png')
            plt.savefig(save_path, dpi=300, bbox_inches='tight')
            plt.close()
            
            print(f"SHAPç€‘å¸ƒå›¾å·²ä¿å­˜åˆ°: {save_path}")
            
        except Exception as e:
            print(f"ç»˜åˆ¶SHAPç€‘å¸ƒå›¾æ—¶å‘ç”Ÿé”™è¯¯: {str(e)}")
            plt.close()
    
    def plot_force_plot(self, sample_idx=0):
        """ç»˜åˆ¶SHAPåŠ›å›¾ï¼ˆå•ä¸ªæ ·æœ¬çš„è§£é‡Šï¼‰"""
        if self.shap_values is None:
            print("è¯·å…ˆè®¡ç®—SHAPå€¼ï¼")
            return
        
        if sample_idx >= len(self.shap_values):
            print(f"æ ·æœ¬ç´¢å¼• {sample_idx} è¶…å‡ºèŒƒå›´ï¼")
            return
        
        print(f"æ­£åœ¨ç”Ÿæˆ{self.model_name}æ¨¡å‹çš„SHAPåŠ›å›¾ï¼ˆæ ·æœ¬ {sample_idx}ï¼‰...")
        
        try:
            # è·å–æœŸæœ›å€¼
            expected_value = self.explainer.expected_value if hasattr(self.explainer, 'expected_value') else 0
            
            # ç»˜åˆ¶åŠ›å›¾
            force_plot = shap.force_plot(
                expected_value,
                self.shap_values[sample_idx],
                self.X_test_sample[sample_idx],
                feature_names=self.english_feature_names,
                matplotlib=True,
                show=False
            )
            
            # ä¿å­˜å›¾ç‰‡
            save_path = os.path.join(self.save_dir, f'shap_force_sample_{sample_idx}.png')
            plt.savefig(save_path, dpi=300, bbox_inches='tight')
            plt.close()
            
            print(f"SHAPåŠ›å›¾å·²ä¿å­˜åˆ°: {save_path}")
            
        except Exception as e:
            print(f"ç»˜åˆ¶SHAPåŠ›å›¾æ—¶å‘ç”Ÿé”™è¯¯: {str(e)}")
            plt.close()
    
    def generate_feature_importance_comparison(self):
        """ç”ŸæˆåŸºäºSHAPçš„ç‰¹å¾é‡è¦æ€§å¯¹æ¯”"""
        if self.shap_values is None:
            print("è¯·å…ˆè®¡ç®—SHAPå€¼ï¼")
            return
        
        print(f"æ­£åœ¨ç”Ÿæˆ{self.model_name}æ¨¡å‹çš„SHAPç‰¹å¾é‡è¦æ€§åˆ†æ...")
        
        try:
            # è®¡ç®—å¹³å‡ç»å¯¹SHAPå€¼ä½œä¸ºç‰¹å¾é‡è¦æ€§
            feature_importance = np.abs(self.shap_values).mean(axis=0)
            
            # åˆ›å»ºç‰¹å¾é‡è¦æ€§DataFrame
            importance_df = pd.DataFrame({
                'Feature': self.english_feature_names,
                'SHAP_Importance': feature_importance
            }).sort_values('SHAP_Importance', ascending=False)
            
            # ç»˜åˆ¶ç‰¹å¾é‡è¦æ€§æ¡å½¢å›¾
            plt.figure(figsize=(10, 6))
            bars = plt.barh(importance_df['Feature'], importance_df['SHAP_Importance'])
            
            # æ·»åŠ æ•°å€¼æ ‡ç­¾
            for i, bar in enumerate(bars):
                width = bar.get_width()
                plt.text(width, bar.get_y() + bar.get_height()/2, 
                        f'{width:.3f}', ha='left', va='center')
            
            plt.xlabel('Mean |SHAP Value|')
            plt.ylabel('Features')
            plt.title(f'{self.model_name} Feature Importance (SHAP-based)')
            plt.tight_layout()
            
            # ä¿å­˜å›¾ç‰‡
            save_path = os.path.join(self.save_dir, 'shap_feature_importance.png')
            plt.savefig(save_path, dpi=300, bbox_inches='tight')
            plt.close()
            
            # ä¿å­˜æ•°æ®
            csv_path = os.path.join(self.save_dir, 'shap_feature_importance.csv')
            importance_df.to_csv(csv_path, index=False)
            
            print(f"SHAPç‰¹å¾é‡è¦æ€§å›¾å·²ä¿å­˜åˆ°: {save_path}")
            print(f"SHAPç‰¹å¾é‡è¦æ€§æ•°æ®å·²ä¿å­˜åˆ°: {csv_path}")
            
            return importance_df
            
        except Exception as e:
            print(f"ç”ŸæˆSHAPç‰¹å¾é‡è¦æ€§æ—¶å‘ç”Ÿé”™è¯¯: {str(e)}")
            return None
    
    def run_complete_analysis(self, max_samples=None, research_mode='fine', plot_dependence=True, plot_individual_samples=True):
        """è¿è¡Œå®Œæ•´çš„SHAPåˆ†æ
        
        Parameters:
        -----------
        max_samples : int, optional
            æœ€å¤§æ ·æœ¬æ•°é‡ï¼Œå¦‚æœä¸ºNoneåˆ™æ ¹æ®research_modeè‡ªåŠ¨é€‰æ‹©
        research_mode : str, default='fine'
            ç ”ç©¶æ¨¡å¼: 'fast'(å¿«é€Ÿ), 'balanced'(å¹³è¡¡), 'fine'(ç²¾ç»†), 'deep'(æ·±åº¦)
        plot_dependence : bool, default=True
            æ˜¯å¦ç»˜åˆ¶ä¾èµ–å›¾
        plot_individual_samples : bool, default=True
            æ˜¯å¦ç»˜åˆ¶ä¸ªåˆ«æ ·æœ¬çš„è§£é‡Šå›¾
        """
        print(f"\nå¼€å§‹å¯¹{self.model_name}æ¨¡å‹è¿›è¡Œå®Œæ•´çš„SHAPå¯è§£é‡Šæ€§åˆ†æ...")
        print(f"ğŸ”¬ ç ”ç©¶æ¨¡å¼: {research_mode.upper()} - {'å¿«é€ŸéªŒè¯' if research_mode=='fast' else 'å¹³è¡¡åˆ†æ' if research_mode=='balanced' else 'ç²¾ç»†ç ”ç©¶' if research_mode=='fine' else 'æ·±åº¦ç ”ç©¶'}")
        
        # 1. è®¡ç®—SHAPå€¼
        if max_samples is None:
            # ä½¿ç”¨æ™ºèƒ½æ¨èçš„æ ·æœ¬æ•°é‡
            if not self.calculate_shap_values():
                print("SHAPå€¼è®¡ç®—å¤±è´¥ï¼Œè·³è¿‡åç»­åˆ†æ")
                return
        else:
            # ä½¿ç”¨ç”¨æˆ·æŒ‡å®šçš„æ ·æœ¬æ•°é‡
            if not self.calculate_shap_values(max_samples=max_samples):
                print("SHAPå€¼è®¡ç®—å¤±è´¥ï¼Œè·³è¿‡åç»­åˆ†æ")
                return
        
        print(f"\nğŸ“Š å®é™…ä½¿ç”¨æ ·æœ¬æ•°é‡: {len(self.X_test_sample)}")
        print(f"ğŸ¯ å¼€å§‹ç”Ÿæˆå¯è§£é‡Šæ€§åˆ†æå›¾è¡¨...")
        
        # 2. ç”Ÿæˆæ‘˜è¦å›¾
        self.plot_summary_plot(plot_type='dot')
        self.plot_summary_plot(plot_type='bar')
        
        # 3. ç”Ÿæˆèœ‚ç¾¤å›¾
        self.plot_beeswarm_plot()
        
        # 4. ç”Ÿæˆä¾èµ–å›¾
        if plot_dependence:
            self.plot_dependence_plots()
        
        # 5. ç”Ÿæˆç‰¹å¾é‡è¦æ€§å¯¹æ¯”
        self.generate_feature_importance_comparison()
        
        # 6. ç”Ÿæˆä¸ªåˆ«æ ·æœ¬çš„è§£é‡Šå›¾
        if plot_individual_samples and len(self.shap_values) > 0:
            # é€‰æ‹©å‡ ä¸ªä»£è¡¨æ€§æ ·æœ¬
            sample_indices = [0]  # ç¬¬ä¸€ä¸ªæ ·æœ¬
            if len(self.shap_values) > 1:
                sample_indices.append(len(self.shap_values) // 2)  # ä¸­é—´æ ·æœ¬
            if len(self.shap_values) > 2:
                sample_indices.append(-1)  # æœ€åä¸€ä¸ªæ ·æœ¬
            
            for idx in sample_indices:
                if idx == -1:
                    idx = len(self.shap_values) - 1
                self.plot_waterfall_plot(idx)
                self.plot_force_plot(idx)
        
        print(f"\nâœ… {self.model_name}æ¨¡å‹çš„SHAPåˆ†æå®Œæˆï¼")
        print(f"ğŸ“ æ‰€æœ‰ç»“æœå·²ä¿å­˜åˆ°: {self.save_dir}")
        
        # ç²¾ç»†ç ”ç©¶æ¨¡å¼çš„é¢å¤–åˆ†ææŠ¥å‘Š
        if research_mode in ['fine', 'deep']:
            self._generate_research_summary()
    
    def _generate_research_summary(self):
        """ç”Ÿæˆç²¾ç»†ç ”ç©¶æ¨¡å¼çš„é¢å¤–åˆ†ææ‘˜è¦"""
        if self.shap_values is None:
            return
        
        try:
            # è®¡ç®—SHAPå€¼çš„ç»Ÿè®¡ä¿¡æ¯
            shap_stats = {
                'mean_abs_shap': np.abs(self.shap_values).mean(axis=0),
                'std_shap': np.std(self.shap_values, axis=0),
                'shap_range': np.max(self.shap_values, axis=0) - np.min(self.shap_values, axis=0)
            }
            
            # ä¿å­˜è¯¦ç»†çš„ç ”ç©¶æŠ¥å‘Š
            report_path = os.path.join(self.save_dir, 'research_summary.txt')
            with open(report_path, 'w', encoding='utf-8') as f:
                f.write(f"=== {self.model_name} ç²¾ç»†ç ”ç©¶SHAPåˆ†ææŠ¥å‘Š ===\n\n")
                f.write(f"åˆ†ææ ·æœ¬æ•°é‡: {len(self.X_test_sample)}\n")
                f.write(f"ç‰¹å¾æ•°é‡: {len(self.english_feature_names)}\n")
                f.write(f"SHAPå€¼å½¢çŠ¶: {self.shap_values.shape}\n\n")
                
                f.write("=== ç‰¹å¾é‡è¦æ€§ç»Ÿè®¡ ===\n")
                for i, feature in enumerate(self.english_feature_names):
                    f.write(f"\n{feature}:\n")
                    f.write(f"  å¹³å‡ç»å¯¹SHAPå€¼: {shap_stats['mean_abs_shap'][i]:.6f}\n")
                    f.write(f"  SHAPå€¼æ ‡å‡†å·®: {shap_stats['std_shap'][i]:.6f}\n")
                    f.write(f"  SHAPå€¼èŒƒå›´: {shap_stats['shap_range'][i]:.6f}\n")
                
                # è®¡ç®—ç‰¹å¾äº¤äº’å¼ºåº¦
                f.write(f"\n=== ç‰¹å¾å½±å“åŠ›æ’å ===\n")
                importance_ranking = np.argsort(shap_stats['mean_abs_shap'])[::-1]
                for rank, idx in enumerate(importance_ranking, 1):
                    feature = self.english_feature_names[idx]
                    importance = shap_stats['mean_abs_shap'][idx]
                    f.write(f"{rank}. {feature}: {importance:.6f}\n")
            
            print(f"ğŸ“‹ ç²¾ç»†ç ”ç©¶æŠ¥å‘Šå·²ä¿å­˜åˆ°: {report_path}")
            
        except Exception as e:
            print(f"ç”Ÿæˆç ”ç©¶æ‘˜è¦æ—¶å‘ç”Ÿé”™è¯¯: {str(e)}")


def run_shap_analysis_for_model(model, X_train, X_test, model_name, feature_names=None, use_gpu=True, max_samples=None, research_mode='fine'):
    """ä¸ºå•ä¸ªæ¨¡å‹è¿è¡ŒSHAPåˆ†æçš„ä¾¿æ·å‡½æ•°
    
    Parameters:
    -----------
    model : sklearn model or similar
        è®­ç»ƒå¥½çš„æ¨¡å‹
    X_train, X_test : array-like
        è®­ç»ƒå’Œæµ‹è¯•æ•°æ®
    model_name : str
        æ¨¡å‹åç§°
    feature_names : list, optional
        ç‰¹å¾åç§°åˆ—è¡¨
    use_gpu : bool, default=True
        æ˜¯å¦ä½¿ç”¨GPUåŠ é€Ÿ
    max_samples : int, optional
        æœ€å¤§æ ·æœ¬æ•°é‡ï¼Œå¦‚æœä¸ºNoneåˆ™è‡ªåŠ¨é€‰æ‹©
    research_mode : str, default='fine'
        ç ”ç©¶æ¨¡å¼: 'fast'(å¿«é€Ÿ), 'balanced'(å¹³è¡¡), 'fine'(ç²¾ç»†), 'deep'(æ·±åº¦)
    """
    analyzer = SHAPAnalyzer(
        model=model,
        X_train=X_train, 
        X_test=X_test,
        feature_names=feature_names,
        model_name=model_name,
        use_gpu=use_gpu
    )
    
    analyzer.run_complete_analysis(max_samples=max_samples, research_mode=research_mode)
    return analyzer 