import streamlit as st
import numpy as np
import pandas as pd
import pickle
import shap
import matplotlib.pyplot as plt
import seaborn as sns
import warnings
import os
import sys
from pathlib import Path

# æœºå™¨å­¦ä¹ åº“
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error
from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor, ExtraTreesRegressor, AdaBoostRegressor
from sklearn.tree import DecisionTreeRegressor
from sklearn.linear_model import LinearRegression, Ridge
from sklearn.svm import SVR
from sklearn.neighbors import KNeighborsRegressor
from sklearn.neural_network import MLPRegressor

# å¯¼å…¥XGBoostå’ŒLightGBMï¼ˆå¦‚æœå¯ç”¨ï¼‰
try:
    import xgboost as xgb
    XGBOOST_AVAILABLE = True
except ImportError:
    XGBOOST_AVAILABLE = False
    
try:
    import lightgbm as lgb
    LIGHTGBM_AVAILABLE = True
except ImportError:
    LIGHTGBM_AVAILABLE = False

# è·å–å½“å‰ç›®å½•è·¯å¾„
current_dir = Path(__file__).parent
sys.path.append(str(current_dir))

warnings.filterwarnings("ignore")

# è®¾ç½®é¡µé¢é…ç½®
st.set_page_config(
    page_title="æŠ‘éƒé‡è¡¨å¾—åˆ†é¢„æµ‹åº”ç”¨",
    page_icon="ğŸ§ ",
    layout="wide",
    initial_sidebar_state="expanded"
)

# è‡ªå®šä¹‰CSSæ ·å¼
st.markdown("""
<style>
    .main-header {
        font-size: 2.5rem;
        color: #1f77b4;
        text-align: center;
        margin-bottom: 2rem;
    }
    .sub-header {
        font-size: 1.5rem;
        color: #ff7f0e;
        margin-top: 2rem;
        margin-bottom: 1rem;
    }
    .prediction-result {
        font-size: 2rem;
        color: #d62728;
        text-align: center;
        padding: 1rem;
        border: 2px solid #d62728;
        border-radius: 10px;
        background-color: #f8f9fa;
        margin: 1rem 0;
    }
    .model-info {
        background-color: #e6f3ff;
        padding: 1rem;
        border-radius: 5px;
        margin: 1rem 0;
    }
    .feature-info {
        background-color: #f0f8ff;
        padding: 0.5rem;
        border-radius: 5px;
        margin: 0.5rem 0;
        font-size: 0.9rem;
    }
</style>
""", unsafe_allow_html=True)

class DepressionPredictionApp:
    def __init__(self):
        self.models = {}
        self.trained_models = {}
        self.background_data = None
        self.X_train = None
        self.X_test = None
        self.y_train = None
        self.y_test = None
        
        # ç‰¹å¾åç§°æ˜ å°„
        self.feature_names = ['äº²å­é‡è¡¨æ€»å¾—åˆ†', 'éŸ§æ€§é‡è¡¨æ€»å¾—åˆ†', 'ç„¦è™‘é‡è¡¨æ€»å¾—åˆ†', 'æ‰‹æœºä½¿ç”¨æ—¶é—´æ€»å¾—åˆ†']
        self.feature_name_mapping = {
            'äº²å­é‡è¡¨æ€»å¾—åˆ†': 'Parent-Child Relationship',
            'éŸ§æ€§é‡è¡¨æ€»å¾—åˆ†': 'Resilience', 
            'ç„¦è™‘é‡è¡¨æ€»å¾—åˆ†': 'Anxiety',
            'æ‰‹æœºä½¿ç”¨æ—¶é—´æ€»å¾—åˆ†': 'Phone Usage Time'
        }
        
        # ç‰¹å¾èŒƒå›´
        self.feature_ranges = {
            'äº²å­é‡è¡¨æ€»å¾—åˆ†': (8, 50),
            'éŸ§æ€§é‡è¡¨æ€»å¾—åˆ†': (0, 40),
            'ç„¦è™‘é‡è¡¨æ€»å¾—åˆ†': (0, 20),
            'æ‰‹æœºä½¿ç”¨æ—¶é—´æ€»å¾—åˆ†': (0, 60)
        }
        
        # æ¨¡å‹æè¿°
        self.model_descriptions = {
            'XGBoost': 'æç«¯æ¢¯åº¦æå‡ï¼Œé«˜æ€§èƒ½æ ‘æ¨¡å‹',
            'LightGBM': 'è½»é‡çº§æ¢¯åº¦æå‡ï¼Œå¿«é€Ÿé«˜æ•ˆ',
            'RandomForest': 'éšæœºæ£®æ—ï¼Œç¨³å®šå¯é ',
            'GradientBoosting': 'æ¢¯åº¦æå‡ï¼Œç»å…¸é›†æˆæ–¹æ³•',
            'ExtraTrees': 'æç«¯éšæœºæ ‘ï¼Œé™ä½è¿‡æ‹Ÿåˆ',
            'SVM': 'æ”¯æŒå‘é‡æœºï¼Œéçº¿æ€§æ˜ å°„',
            'ANN': 'äººå·¥ç¥ç»ç½‘ç»œï¼Œæ·±åº¦å­¦ä¹ ',
            'KNN': 'Kè¿‘é‚»ç®—æ³•ï¼ŒåŸºäºç›¸ä¼¼æ€§',
            'DecisionTree': 'å†³ç­–æ ‘ï¼Œå¯è§£é‡Šæ€§å¼º',
            'AdaBoost': 'è‡ªé€‚åº”æå‡ï¼Œé”™è¯¯åŠ æƒ',
            'LinearRegression': 'çº¿æ€§å›å½’ï¼ŒåŸºç¡€æ¨¡å‹',
            'Ridge': 'å²­å›å½’ï¼Œæ­£åˆ™åŒ–çº¿æ€§æ¨¡å‹'
        }
        
        # åˆå§‹åŒ–
        self.load_data()
        self.load_models()
        
    def load_data(self):
        """åŠ è½½æ•°æ®"""
        try:
            data_path = current_dir / 'data' / 'é‡è¡¨æ€»åˆ†å®Œæ•´æ•°æ®.csv'
            if data_path.exists():
                df = pd.read_csv(data_path)
                
                # å‡†å¤‡ç‰¹å¾å’Œç›®æ ‡å˜é‡
                X = df[self.feature_names]
                y = df['æŠ‘éƒé‡è¡¨æ€»å¾—åˆ†']
                
                # åˆ†å‰²æ•°æ®
                self.X_train, self.X_test, self.y_train, self.y_test = train_test_split(
                    X, y, test_size=0.2, random_state=42
                )
                
                # éšæœºé‡‡æ ·1000ä¸ªæ ·æœ¬ä½œä¸ºèƒŒæ™¯æ•°æ®
                self.background_data = X.sample(n=min(1000, len(X)), random_state=42)
                
                st.success(f"âœ… æ•°æ®åŠ è½½æˆåŠŸï¼è®­ç»ƒé›†: {len(self.X_train)} æ ·æœ¬ï¼Œæµ‹è¯•é›†: {len(self.X_test)} æ ·æœ¬")
            else:
                st.error("âŒ æ‰¾ä¸åˆ°æ•°æ®æ–‡ä»¶")
                return False
        except Exception as e:
            st.error(f"âŒ åŠ è½½æ•°æ®å¤±è´¥: {e}")
            return False
        return True
    
    def load_models(self):
        """åŠ è½½è®­ç»ƒå¥½çš„æ¨¡å‹"""
        models_dir = current_dir / 'models'
        
        # æ¨¡å‹æ–‡ä»¶åæ˜ å°„
        model_files = {
            'XGBoost': 'XGBoost_model.pkl',
            'LightGBM': 'LightGBM_model.pkl',
            'RandomForest': 'RandomForest_model.pkl',
            'GradientBoosting': 'GradientBoosting_model.pkl',
            'ExtraTrees': 'ExtraTrees_model.pkl',
            'SVM': 'SVM_model.pkl',
            'ANN': 'ANN_model.pkl',
            'KNN': 'KNN_model.pkl',
            'DecisionTree': 'DecisionTree_model.pkl',
            'AdaBoost': 'AdaBoost_model.pkl',
            'LinearRegression': 'LinearRegression_model.pkl',
            'Ridge': 'Ridge_model.pkl'
        }
        
        loaded_count = 0
        failed_count = 0
        
        for model_name, file_name in model_files.items():
            model_path = models_dir / file_name
            if model_path.exists():
                try:
                    with open(model_path, 'rb') as f:
                        self.models[model_name] = pickle.load(f)
                    loaded_count += 1
                except Exception as e:
                    st.warning(f"âš ï¸ æ— æ³•åŠ è½½æ¨¡å‹ {model_name}: {e}")
                    failed_count += 1
        
        if loaded_count > 0:
            st.info(f"ğŸ“Š æˆåŠŸåŠ è½½ {loaded_count} ä¸ªé¢„è®­ç»ƒæ¨¡å‹ï¼Œ{failed_count} ä¸ªæ¨¡å‹åŠ è½½å¤±è´¥")
        else:
            st.warning("âš ï¸ æ²¡æœ‰å¯ç”¨çš„é¢„è®­ç»ƒæ¨¡å‹ï¼Œå°†ä½¿ç”¨å®æ—¶è®­ç»ƒåŠŸèƒ½")
    
    def train_fresh_models(self, selected_models):
        """è®­ç»ƒæ–°çš„æ¨¡å‹"""
        if self.X_train is None or self.y_train is None:
            st.error("âŒ è®­ç»ƒæ•°æ®ä¸å¯ç”¨")
            return {}
        
        trained_models = {}
        
        # å®šä¹‰æ¨¡å‹
        model_definitions = {
            'RandomForest': RandomForestRegressor(n_estimators=100, random_state=42),
            'GradientBoosting': GradientBoostingRegressor(n_estimators=100, random_state=42),
            'ExtraTrees': ExtraTreesRegressor(n_estimators=100, random_state=42),
            'DecisionTree': DecisionTreeRegressor(random_state=42),
            'AdaBoost': AdaBoostRegressor(n_estimators=100, random_state=42),
            'LinearRegression': LinearRegression(),
            'Ridge': Ridge(alpha=1.0),
            'SVM': SVR(kernel='rbf', C=1.0),
            'KNN': KNeighborsRegressor(n_neighbors=5),
            'ANN': MLPRegressor(hidden_layer_sizes=(100, 50), max_iter=500, random_state=42)
        }
        
        # æ·»åŠ XGBoostï¼ˆå¦‚æœå¯ç”¨ï¼‰
        if XGBOOST_AVAILABLE:
            model_definitions['XGBoost'] = xgb.XGBRegressor(n_estimators=100, random_state=42)
        
        # æ·»åŠ LightGBMï¼ˆå¦‚æœå¯ç”¨ï¼‰
        if LIGHTGBM_AVAILABLE:
            model_definitions['LightGBM'] = lgb.LGBMRegressor(n_estimators=100, random_state=42, verbose=-1)
        
        progress_bar = st.progress(0)
        status_text = st.empty()
        
        for i, model_name in enumerate(selected_models):
            if model_name in model_definitions:
                try:
                    status_text.text(f"æ­£åœ¨è®­ç»ƒ {model_name} æ¨¡å‹...")
                    
                    model = model_definitions[model_name]
                    model.fit(self.X_train, self.y_train)
                    
                    # è¯„ä¼°æ¨¡å‹
                    y_pred = model.predict(self.X_test)
                    mse = mean_squared_error(self.y_test, y_pred)
                    r2 = r2_score(self.y_test, y_pred)
                    
                    trained_models[model_name] = {
                        'model': model,
                        'mse': mse,
                        'r2': r2
                    }
                    
                    progress_bar.progress((i + 1) / len(selected_models))
                    
                except Exception as e:
                    st.warning(f"âš ï¸ è®­ç»ƒæ¨¡å‹ {model_name} å¤±è´¥: {e}")
        
        status_text.text("âœ… æ¨¡å‹è®­ç»ƒå®Œæˆï¼")
        progress_bar.empty()
        
        return trained_models
    
    def create_shap_waterfall_plot(self, shap_values, expected_value, feature_values, feature_names):
        """åˆ›å»ºSHAPç€‘å¸ƒå›¾"""
        fig, ax = plt.subplots(figsize=(10, 6))
        
        # å‡†å¤‡æ•°æ®
        values = shap_values[0] if len(shap_values.shape) > 1 else shap_values
        features = [f"{name} = {val:.1f}" for name, val in zip(feature_names, feature_values)]
        
        # ç»˜åˆ¶åŸºå‡†çº¿
        ax.axhline(y=expected_value, color='gray', linestyle='--', alpha=0.7, label=f'åŸºå‡†å€¼: {expected_value:.2f}')
        
        # ç»˜åˆ¶ç‰¹å¾è´¡çŒ®
        positions = range(len(features))
        colors = ['red' if val < 0 else 'blue' for val in values]
        
        # ç»˜åˆ¶æ¡å½¢å›¾
        bars = ax.bar(positions, np.abs(values), color=colors, alpha=0.7)
        
        # æ·»åŠ æ•°å€¼æ ‡ç­¾
        for i, (bar, val) in enumerate(zip(bars, values)):
            height = bar.get_height()
            ax.text(bar.get_x() + bar.get_width()/2., height + 0.05,
                   f'{val:+.2f}', ha='center', va='bottom', fontsize=10)
        
        # è®¾ç½®æ ‡ç­¾å’Œæ ‡é¢˜
        ax.set_xticks(positions)
        ax.set_xticklabels(features, rotation=45, ha='right')
        ax.set_ylabel('SHAPå€¼ (å¯¹é¢„æµ‹çš„å½±å“)')
        ax.set_title('SHAPç‰¹å¾è´¡çŒ®åˆ†æ - å„ç‰¹å¾å¯¹é¢„æµ‹ç»“æœçš„å½±å“')
        
        # æ·»åŠ é¢„æµ‹ç»“æœçº¿
        final_prediction = expected_value + sum(values)
        ax.axhline(y=final_prediction, color='green', linestyle='-', linewidth=2, 
                  label=f'é¢„æµ‹ç»“æœ: {final_prediction:.2f}')
        
        ax.legend()
        ax.grid(True, alpha=0.3)
        plt.tight_layout()
        
        return fig
    
    def run_shap_analysis(self, model, model_name, input_data):
        """è¿è¡ŒSHAPåˆ†æ"""
        if self.background_data is None:
            st.error("âŒ èƒŒæ™¯æ•°æ®æœªåŠ è½½ï¼Œæ— æ³•è¿›è¡ŒSHAPåˆ†æ")
            return None
        
        try:
            # åˆå§‹åŒ–SHAPè§£é‡Šå™¨
            if model_name in ['XGBoost', 'LightGBM', 'RandomForest', 'GradientBoosting', 
                            'ExtraTrees', 'DecisionTree', 'AdaBoost']:
                explainer = shap.TreeExplainer(model)
                shap_values = explainer.shap_values(input_data)
            else:
                # å¯¹äºå…¶ä»–æ¨¡å‹ä½¿ç”¨KernelExplainer
                explainer = shap.KernelExplainer(model.predict, self.background_data.sample(100))
                shap_values = explainer.shap_values(input_data)
            
            expected_value = explainer.expected_value
            if hasattr(expected_value, '__len__') and len(expected_value) > 1:
                expected_value = expected_value[0]
            
            return shap_values, expected_value, explainer
            
        except Exception as e:
            st.error(f"âŒ SHAPåˆ†æå¤±è´¥: {e}")
            return None
    
    def render_sidebar(self):
        """æ¸²æŸ“ä¾§è¾¹æ """
        st.sidebar.header("ğŸ”§ æ¨¡å‹é€‰æ‹©")
        
        # æ˜¾ç¤ºå¯ç”¨æ¨¡å‹çŠ¶æ€
        if self.models:
            st.sidebar.success(f"âœ… {len(self.models)} ä¸ªé¢„è®­ç»ƒæ¨¡å‹å¯ç”¨")
        else:
            st.sidebar.warning("âš ï¸ æ— é¢„è®­ç»ƒæ¨¡å‹ï¼Œå°†å®æ—¶è®­ç»ƒ")
        
        # æ¨¡å‹é€‰æ‹©
        available_models = list(self.model_descriptions.keys())
        selected_models = st.sidebar.multiselect(
            "é€‰æ‹©è¦ä½¿ç”¨çš„æ¨¡å‹ï¼š",
            available_models,
            default=['XGBoost', 'LightGBM', 'RandomForest'] if not self.models else list(self.models.keys())[:3],
            help="é€‰æ‹©ä¸€ä¸ªæˆ–å¤šä¸ªæ¨¡å‹è¿›è¡Œé¢„æµ‹"
        )
        
        # è®­ç»ƒé€‰é¡¹
        if not self.models or st.sidebar.checkbox("é‡æ–°è®­ç»ƒæ¨¡å‹"):
            self.use_fresh_training = True
        else:
            self.use_fresh_training = False
        
        return selected_models
    
    def render_input_form(self):
        """æ¸²æŸ“è¾“å…¥è¡¨å•"""
        st.markdown('<div class="sub-header">ğŸ“Š ç‰¹å¾è¾“å…¥</div>', unsafe_allow_html=True)
        
        col1, col2 = st.columns(2)
        
        with col1:
            # äº²å­é‡è¡¨å¾—åˆ†
            st.markdown('<div class="feature-info">äº²å­é‡è¡¨æ€»å¾—åˆ† (èŒƒå›´: 8-50)</div>', 
                       unsafe_allow_html=True)
            parent_child = st.number_input(
                "äº²å­é‡è¡¨æ€»å¾—åˆ†",
                min_value=8, max_value=50, value=None,
                step=1, help="è¯·è¾“å…¥8-50ä¹‹é—´çš„æ•´æ•°"
            )
            
            # ç„¦è™‘é‡è¡¨å¾—åˆ†
            st.markdown('<div class="feature-info">ç„¦è™‘é‡è¡¨æ€»å¾—åˆ† (èŒƒå›´: 0-20)</div>', 
                       unsafe_allow_html=True)
            anxiety = st.number_input(
                "ç„¦è™‘é‡è¡¨æ€»å¾—åˆ†",
                min_value=0, max_value=20, value=None,
                step=1, help="è¯·è¾“å…¥0-20ä¹‹é—´çš„æ•´æ•°"
            )
        
        with col2:
            # éŸ§æ€§é‡è¡¨å¾—åˆ†
            st.markdown('<div class="feature-info">éŸ§æ€§é‡è¡¨æ€»å¾—åˆ† (èŒƒå›´: 0-40)</div>', 
                       unsafe_allow_html=True)
            resilience = st.number_input(
                "éŸ§æ€§é‡è¡¨æ€»å¾—åˆ†",
                min_value=0, max_value=40, value=None,
                step=1, help="è¯·è¾“å…¥0-40ä¹‹é—´çš„æ•´æ•°"
            )
            
            # æ‰‹æœºä½¿ç”¨æ—¶é—´å¾—åˆ†
            st.markdown('<div class="feature-info">æ‰‹æœºä½¿ç”¨æ—¶é—´æ€»å¾—åˆ† (èŒƒå›´: 0-60)</div>', 
                       unsafe_allow_html=True)
            phone_usage = st.number_input(
                "æ‰‹æœºä½¿ç”¨æ—¶é—´æ€»å¾—åˆ†",
                min_value=0, max_value=60, value=None,
                step=1, help="è¯·è¾“å…¥0-60ä¹‹é—´çš„æ•´æ•°"
            )
        
        return parent_child, resilience, anxiety, phone_usage
    
    def validate_inputs(self, parent_child, resilience, anxiety, phone_usage):
        """éªŒè¯è¾“å…¥"""
        if any(val is None for val in [parent_child, resilience, anxiety, phone_usage]):
            return False, "è¯·å¡«å†™æ‰€æœ‰ç‰¹å¾å€¼"
        return True, ""
    
    def run_predictions(self, selected_models, input_data):
        """è¿è¡Œé¢„æµ‹"""
        predictions = {}
        
        # å¦‚æœéœ€è¦é‡æ–°è®­ç»ƒæˆ–æ²¡æœ‰é¢„è®­ç»ƒæ¨¡å‹
        if self.use_fresh_training or not self.models:
            st.info("ğŸ”„ æ­£åœ¨è®­ç»ƒæ–°æ¨¡å‹...")
            self.trained_models = self.train_fresh_models(selected_models)
            
            for model_name in selected_models:
                if model_name in self.trained_models:
                    try:
                        model_info = self.trained_models[model_name]
                        pred = model_info['model'].predict(input_data)[0]
                        predictions[model_name] = pred
                    except Exception as e:
                        st.error(f"âŒ æ¨¡å‹ {model_name} é¢„æµ‹å¤±è´¥: {e}")
        else:
            # ä½¿ç”¨é¢„è®­ç»ƒæ¨¡å‹
            for model_name in selected_models:
                if model_name in self.models:
                    try:
                        pred = self.models[model_name].predict(input_data)[0]
                        predictions[model_name] = pred
                    except Exception as e:
                        st.error(f"âŒ æ¨¡å‹ {model_name} é¢„æµ‹å¤±è´¥: {e}")
        
        return predictions
    
    def render_results(self, predictions, input_data, selected_models):
        """æ¸²æŸ“é¢„æµ‹ç»“æœ"""
        if not predictions:
            st.warning("âŒ æ²¡æœ‰å¯ç”¨çš„é¢„æµ‹ç»“æœ")
            return
        
        # æ˜¾ç¤ºé¢„æµ‹ç»“æœ
        st.markdown('<div class="sub-header">ğŸ¯ é¢„æµ‹ç»“æœ</div>', unsafe_allow_html=True)
        
        # è®¡ç®—å¹³å‡é¢„æµ‹
        avg_prediction = np.mean(list(predictions.values()))
        
        st.markdown(f'''
        <div class="prediction-result">
            å¹³å‡é¢„æµ‹çš„æŠ‘éƒé‡è¡¨å¾—åˆ†: {avg_prediction:.2f}
        </div>
        ''', unsafe_allow_html=True)
        
        # æ˜¾ç¤ºå„æ¨¡å‹é¢„æµ‹ç»“æœ
        col1, col2 = st.columns(2)
        
        with col1:
            st.subheader("ğŸ“ˆ å„æ¨¡å‹é¢„æµ‹ç»“æœ")
            results_df = pd.DataFrame({
                'æ¨¡å‹': list(predictions.keys()),
                'é¢„æµ‹å¾—åˆ†': [f"{pred:.2f}" for pred in predictions.values()]
            })
            st.dataframe(results_df, use_container_width=True)
        
        with col2:
            st.subheader("ğŸ“Š é¢„æµ‹åˆ†å¸ƒ")
            fig, ax = plt.subplots(figsize=(8, 6))
            ax.bar(range(len(predictions)), list(predictions.values()), 
                  color='skyblue', alpha=0.7)
            ax.axhline(y=avg_prediction, color='red', linestyle='--', 
                      label=f'å¹³å‡å€¼: {avg_prediction:.2f}')
            ax.set_xticks(range(len(predictions)))
            ax.set_xticklabels(list(predictions.keys()), rotation=45, ha='right')
            ax.set_ylabel('é¢„æµ‹å¾—åˆ†')
            ax.set_title('å„æ¨¡å‹é¢„æµ‹ç»“æœå¯¹æ¯”')
            ax.legend()
            ax.grid(True, alpha=0.3)
            plt.tight_layout()
            st.pyplot(fig)
        
        # SHAPåˆ†æ
        self.render_shap_analysis(input_data, selected_models)
    
    def render_shap_analysis(self, input_data, selected_models):
        """æ¸²æŸ“SHAPåˆ†æ"""
        st.markdown('<div class="sub-header">ğŸ” SHAPè§£é‡Šæ€§åˆ†æ</div>', unsafe_allow_html=True)
        
        # é€‰æ‹©è¦åˆ†æçš„æ¨¡å‹
        available_models = []
        if self.use_fresh_training or not self.models:
            available_models = [name for name in selected_models if name in self.trained_models]
        else:
            available_models = [name for name in selected_models if name in self.models]
        
        if not available_models:
            st.warning("âŒ æ²¡æœ‰å¯ç”¨äºSHAPåˆ†æçš„æ¨¡å‹")
            return
        
        shap_model = st.selectbox(
            "é€‰æ‹©è¦è¿›è¡ŒSHAPåˆ†æçš„æ¨¡å‹ï¼š",
            available_models,
            help="é€‰æ‹©ä¸€ä¸ªæ¨¡å‹æ¥æŸ¥çœ‹å…¶é¢„æµ‹çš„è¯¦ç»†è§£é‡Š"
        )
        
        if shap_model:
            # è·å–æ¨¡å‹
            if self.use_fresh_training or not self.models:
                model = self.trained_models[shap_model]['model']
            else:
                model = self.models[shap_model]
            
            with st.spinner(f"æ­£åœ¨ä¸º{shap_model}æ¨¡å‹ç”ŸæˆSHAPåˆ†æ..."):
                shap_result = self.run_shap_analysis(model, shap_model, input_data)
                
                if shap_result:
                    shap_values, expected_value, explainer = shap_result
                    
                    # å‡†å¤‡ç‰¹å¾å€¼å’Œåç§°
                    feature_values = input_data.iloc[0].values
                    english_names = [self.feature_name_mapping[name] for name in self.feature_names]
                    
                    # åˆ›å»ºç€‘å¸ƒå›¾
                    st.subheader("ğŸŒŠ SHAPç€‘å¸ƒå›¾ - ç‰¹å¾è´¡çŒ®åˆ†æ")
                    
                    waterfall_fig = self.create_shap_waterfall_plot(
                        shap_values, expected_value, feature_values, english_names
                    )
                    st.pyplot(waterfall_fig)
                    
                    # æ˜¾ç¤ºè¯¦ç»†çš„SHAPå€¼
                    st.subheader("ğŸ“‹ è¯¦ç»†SHAPåˆ†æ")
                    
                    # å‡†å¤‡SHAPæ•°æ®
                    if len(shap_values.shape) > 1:
                        shap_vals = shap_values[0]
                    else:
                        shap_vals = shap_values
                    
                    shap_df = pd.DataFrame({
                        'ç‰¹å¾': english_names,
                        'ç‰¹å¾å€¼': feature_values,
                        'SHAPå€¼': shap_vals,
                        'è´¡çŒ®ç¨‹åº¦': ['æ­£å‘' if val > 0 else 'è´Ÿå‘' for val in shap_vals],
                        'å½±å“å¤§å°': np.abs(shap_vals)
                    }).sort_values('å½±å“å¤§å°', ascending=False)
                    
                    st.dataframe(shap_df, use_container_width=True)
                    
                    # è§£é‡Šè¯´æ˜
                    st.info("""
                    **SHAPåˆ†æè§£é‡Šï¼š**
                    - **åŸºå‡†å€¼**: æ¨¡å‹åœ¨è®­ç»ƒæ•°æ®ä¸Šçš„å¹³å‡é¢„æµ‹å€¼
                    - **SHAPå€¼**: æ¯ä¸ªç‰¹å¾å¯¹æœ€ç»ˆé¢„æµ‹çš„è´¡çŒ®ï¼Œæ­£å€¼è¡¨ç¤ºå¢åŠ é¢„æµ‹å€¼ï¼Œè´Ÿå€¼è¡¨ç¤ºå‡å°‘é¢„æµ‹å€¼
                    - **é¢„æµ‹ç»“æœ**: åŸºå‡†å€¼åŠ ä¸Šæ‰€æœ‰ç‰¹å¾çš„SHAPå€¼ä¹‹å’Œ
                    - **ç‰¹å¾é‡è¦æ€§**: æŒ‰ç…§SHAPå€¼çš„ç»å¯¹å€¼å¤§å°æ’åºï¼Œå€¼è¶Šå¤§è¡¨ç¤ºè¯¥ç‰¹å¾å¯¹é¢„æµ‹ç»“æœçš„å½±å“è¶Šå¤§
                    """)
    
    def run(self):
        """è¿è¡Œåº”ç”¨ä¸»ç¨‹åº"""
        # é¡µé¢æ ‡é¢˜
        st.markdown('<div class="main-header">ğŸ§  æŠ‘éƒé‡è¡¨å¾—åˆ†é¢„æµ‹åº”ç”¨</div>', 
                   unsafe_allow_html=True)
        
        # åº”ç”¨è¯´æ˜
        st.markdown("""
        <div class="model-info">
        <h4>ğŸ“‹ åº”ç”¨è¯´æ˜</h4>
        <p>æœ¬åº”ç”¨ä½¿ç”¨å¤šç§æœºå™¨å­¦ä¹ æ¨¡å‹æ¥é¢„æµ‹æŠ‘éƒé‡è¡¨å¾—åˆ†ã€‚å¯ä»¥ä½¿ç”¨é¢„è®­ç»ƒæ¨¡å‹æˆ–å®æ—¶è®­ç»ƒæ–°æ¨¡å‹ã€‚</p>
        <p><strong>ç‰¹å¾è¯´æ˜ï¼š</strong></p>
        <ul>
            <li><strong>äº²å­é‡è¡¨æ€»å¾—åˆ†</strong>: åæ˜ äº²å­å…³ç³»è´¨é‡ (8-50åˆ†)</li>
            <li><strong>éŸ§æ€§é‡è¡¨æ€»å¾—åˆ†</strong>: åæ˜ å¿ƒç†éŸ§æ€§æ°´å¹³ (0-40åˆ†)</li>
            <li><strong>ç„¦è™‘é‡è¡¨æ€»å¾—åˆ†</strong>: åæ˜ ç„¦è™‘ç¨‹åº¦ (0-20åˆ†)</li>
            <li><strong>æ‰‹æœºä½¿ç”¨æ—¶é—´æ€»å¾—åˆ†</strong>: åæ˜ æ‰‹æœºä½¿ç”¨æƒ…å†µ (0-60åˆ†)</li>
        </ul>
        </div>
        """, unsafe_allow_html=True)
        
        # ä¾§è¾¹æ ï¼šæ¨¡å‹é€‰æ‹©
        selected_models = self.render_sidebar()
        
        if not selected_models:
            st.warning("âš ï¸ è¯·åœ¨å·¦ä¾§é€‰æ‹©è‡³å°‘ä¸€ä¸ªæ¨¡å‹è¿›è¡Œé¢„æµ‹")
            return
        
        # æ˜¾ç¤ºå·²é€‰æ‹©çš„æ¨¡å‹
        st.markdown(f"**å·²é€‰æ‹©æ¨¡å‹**: {', '.join(selected_models)}")
        
        # è¾“å…¥è¡¨å•
        parent_child, resilience, anxiety, phone_usage = self.render_input_form()
        
        # é¢„æµ‹æŒ‰é’®
        if st.button("ğŸš€ å¼€å§‹é¢„æµ‹", type="primary", use_container_width=True):
            # éªŒè¯è¾“å…¥
            is_valid, error_msg = self.validate_inputs(parent_child, resilience, anxiety, phone_usage)
            
            if not is_valid:
                st.error(error_msg)
                return
            
            # å‡†å¤‡è¾“å…¥æ•°æ®
            input_data = pd.DataFrame({
                'äº²å­é‡è¡¨æ€»å¾—åˆ†': [parent_child],
                'éŸ§æ€§é‡è¡¨æ€»å¾—åˆ†': [resilience],
                'ç„¦è™‘é‡è¡¨æ€»å¾—åˆ†': [anxiety],
                'æ‰‹æœºä½¿ç”¨æ—¶é—´æ€»å¾—åˆ†': [phone_usage]
            })
            
            # è¿è¡Œé¢„æµ‹
            with st.spinner("æ­£åœ¨è¿›è¡Œé¢„æµ‹..."):
                predictions = self.run_predictions(selected_models, input_data)
            
            # æ˜¾ç¤ºç»“æœ
            self.render_results(predictions, input_data, selected_models)

# è¿è¡Œåº”ç”¨
if __name__ == "__main__":
    app = DepressionPredictionApp()
    app.run() 